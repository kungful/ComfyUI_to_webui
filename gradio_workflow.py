import json
import time
import random
import requests
import shutil
from collections import Counter, deque # å¯¼å…¥ deque
from PIL import Image, ImageSequence, ImageOps
import re
import io # å¯¼å…¥ io ç”¨äºæ›´ç²¾ç¡®çš„æ–‡ä»¶å¤„ç†
import gradio as gr
from packaging import version
import numpy as np
import torch
import threading
from threading import Lock, Event # å¯¼å…¥ Lock å’Œ Event
from concurrent.futures import ThreadPoolExecutor
import websocket # æ·»åŠ  websocket å¯¼å…¥
import atexit # For NVML cleanup
from .kelnel_ui.system_monitor import update_floating_monitors_stream, custom_css as monitor_css, cleanup_nvml # ç³»ç»Ÿç›‘æ§æ¨¡å—
from .kelnel_ui.k_Preview import ComfyUIPreviewer # <--- å¯¼å…¥ ComfyUIPreviewer
from .kelnel_ui.css_html_js import HACKER_CSS, get_sponsor_html # <--- ä» css_html_js.py å¯¼å…¥
from .kelnel_ui.ui_def import ( # <--- ä» ui_def.py å¯¼å…¥
    calculate_aspect_ratio,
    strip_prefix,
    parse_resolution,
    load_resolution_presets_from_files,
    find_closest_preset,
    get_output_images,
    # fuck, # Removed as it's deprecated and its logic is integrated elsewhere
    get_workflow_defaults_and_visibility
)
# å¯¼å…¥æ–°çš„é…ç½®ç®¡ç†å‡½æ•°å’Œå¸¸é‡
from .kelnel_ui.ui_def import (
    load_plugin_settings, 
    save_plugin_settings, 
    DEFAULT_MAX_DYNAMIC_COMPONENTS # éœ€è¦è¿™ä¸ªä½œä¸º MAX_DYNAMIC_COMPONENTS çš„å¤‡ç”¨å€¼
)

# --- åˆå§‹åŒ–æœ€å¤§åŠ¨æ€ç»„ä»¶æ•°é‡ (ä» kelnel_ui.ui_def å¯¼å…¥çš„å‡½æ•°åŠ è½½) ---
plugin_settings_on_load = load_plugin_settings() 
MAX_DYNAMIC_COMPONENTS = plugin_settings_on_load.get("max_dynamic_components", DEFAULT_MAX_DYNAMIC_COMPONENTS)
print(f"æ’ä»¶å¯åŠ¨ï¼šæœ€å¤§åŠ¨æ€ç»„ä»¶æ•°é‡ä»é…ç½®åŠ è½½ä¸º: {MAX_DYNAMIC_COMPONENTS} (é€šè¿‡ kelnel_ui.ui_def)")
# --- åˆå§‹åŒ–æœ€å¤§åŠ¨æ€ç»„ä»¶æ•°é‡ç»“æŸ ---

# Register NVML cleanup function to be called on exit
atexit.register(cleanup_nvml)

# --- æ—¥å¿—è½®è¯¢å¯¼å…¥ ---
import requests # requests å¯èƒ½å·²å¯¼å…¥ï¼Œç¡®è®¤ä¸€ä¸‹
import json # json å¯èƒ½å·²å¯¼å…¥ï¼Œç¡®è®¤ä¸€ä¸‹
import time # time å¯èƒ½å·²å¯¼å…¥ï¼Œç¡®è®¤ä¸€ä¸‹
# --- æ—¥å¿—è½®è¯¢å¯¼å…¥ç»“æŸ ---
import folder_paths
import node_helpers
from pathlib import Path
from server import PromptServer
from server import BinaryEventTypes
import sys
import os
import webbrowser
import glob
from datetime import datetime
from math import gcd
import uuid
import fnmatch
from .kelnel_ui.gradio_cancel_test import cancel_comfyui_task_action # <--- å¯¼å…¥ä¸­æ–­å‡½æ•°
from .kelnel_ui.api_json_manage import define_api_json_management_ui # <--- å¯¼å…¥ API JSON ç®¡ç† UI å®šä¹‰å‡½æ•°

# --- å…¨å±€çŠ¶æ€å˜é‡ ---
task_queue = deque()
queue_lock = Lock()
accumulated_image_results = [] # æ˜ç¡®ç”¨äºå›¾ç‰‡
last_video_result = None # ç”¨äºå­˜å‚¨æœ€æ–°çš„è§†é¢‘è·¯å¾„
results_lock = Lock()
processing_event = Event() # False: ç©ºé—², True: æ­£åœ¨å¤„ç†
executor = ThreadPoolExecutor(max_workers=1) # å•çº¿ç¨‹æ‰§è¡Œç”Ÿæˆä»»åŠ¡
last_used_seed = -1 # ç”¨äºé€’å¢/é€’å‡æ¨¡å¼
seed_lock = Lock() # ç”¨äºä¿æŠ¤ last_used_seed
interrupt_requested_event = Event() # æ–°å¢ï¼šç”¨äºç”¨æˆ·è¯·æ±‚ä¸­æ–­å½“å‰ä»»åŠ¡çš„ä¿¡å·

# --- ComfyUI å®æ—¶é¢„è§ˆå™¨å®ä¾‹ ---
# ä½¿ç”¨ä¸€ä¸ªç‹¬ç‰¹çš„ client_id_suffix ä»¥é¿å…ä¸ k_Preview.py çš„ç‹¬ç«‹æµ‹è¯•å†²çª
comfyui_previewer = ComfyUIPreviewer(client_id_suffix="gradio_workflow_integration", min_yield_interval=0.1)
# --- å…¨å±€çŠ¶æ€å˜é‡ç»“æŸ ---

# --- æ—¥å¿—è½®è¯¢å…¨å±€å˜é‡å’Œå‡½æ•° ---
COMFYUI_LOG_URL = "http://127.0.0.1:8188/internal/logs/raw"
all_logs_text = ""

def fetch_and_format_logs():
    global all_logs_text

    try:
        response = requests.get(COMFYUI_LOG_URL, timeout=5)
        response.raise_for_status()
        data = response.json()
        log_entries = data.get("entries", [])

        # ç§»é™¤å¤šä½™ç©ºè¡Œå¹¶åˆå¹¶æ—¥å¿—å†…å®¹
        formatted_logs = "\n".join(filter(None, [entry.get('m', '').strip() for entry in log_entries]))
        all_logs_text = formatted_logs

        return all_logs_text

    except requests.exceptions.RequestException as e:
        error_message = f"æ— æ³•è¿æ¥åˆ° ComfyUI æœåŠ¡å™¨: {e}"
        return all_logs_text + "\n" + error_message if all_logs_text else error_message
    except json.JSONDecodeError:
        error_message = "æ— æ³•è§£ææœåŠ¡å™¨å“åº” (é JSON)"
        return all_logs_text + "\n" + error_message if all_logs_text else error_message
    except Exception as e:
        error_message = f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"
        return all_logs_text + "\n" + error_message if all_logs_text else error_message

# --- æ—¥å¿—è½®è¯¢å…¨å±€å˜é‡å’Œå‡½æ•°ç»“æŸ ---

# --- ComfyUI èŠ‚ç‚¹å¾½ç« è®¾ç½® ---
# å°è¯•ä¸¤ç§å¯èƒ½çš„ API è·¯å¾„
COMFYUI_API_NODE_BADGE = "http://127.0.0.1:8188/settings/Comfy.NodeBadge.NodeIdBadgeMode"
# COMFYUI_API_NODE_BADGE = "http://127.0.0.1:8188/api/settings/Comfy.NodeBadge.NodeIdBadgeMode" # å¤‡ç”¨è·¯å¾„

def update_node_badge_mode(mode):
    """å‘é€ POST è¯·æ±‚æ›´æ–° NodeIdBadgeMode"""
    try:
        # ç›´æ¥å°è¯• JSON æ ¼å¼
        response = requests.post(
            COMFYUI_API_NODE_BADGE,
            json=mode,  # ä½¿ç”¨ json å‚æ•°è‡ªåŠ¨è®¾ç½® Content-Type ä¸º application/json
        )

        if response.status_code == 200:
            return f"âœ… æˆåŠŸæ›´æ–°èŠ‚ç‚¹å¾½ç« æ¨¡å¼ä¸º: {mode}"
        else:
            # å°è¯•è§£æé”™è¯¯ä¿¡æ¯
            try:
                error_detail = response.json() # å°è¯•è§£æ JSON é”™è¯¯
                error_text = error_detail.get('error', response.text)
                error_traceback = error_detail.get('traceback', '')
                return f"âŒ æ›´æ–°å¤±è´¥ (HTTP {response.status_code}): {error_text}\n{error_traceback}".strip()
            except json.JSONDecodeError: # å¦‚æœä¸æ˜¯ JSON é”™è¯¯
                return f"âŒ æ›´æ–°å¤±è´¥ (HTTP {response.status_code}): {response.text}"
    except requests.exceptions.ConnectionError:
         return f"âŒ è¯·æ±‚å‡ºé”™: æ— æ³•è¿æ¥åˆ° ComfyUI æœåŠ¡å™¨ ({COMFYUI_API_NODE_BADGE})ã€‚è¯·ç¡®ä¿ ComfyUI æ­£åœ¨è¿è¡Œã€‚"
    except Exception as e:
        return f"âŒ è¯·æ±‚å‡ºé”™: {str(e)}"
# --- ComfyUI èŠ‚ç‚¹å¾½ç« è®¾ç½®ç»“æŸ ---

# --- é‡å¯å’Œä¸­æ–­å‡½æ•° ---
COMFYUI_DEFAULT_URL_FOR_WORKFLOW = "http://127.0.0.1:8188" # å®šä¹‰ ComfyUI URL å¸¸é‡

def reboot_manager():
    try:
        # å‘é€é‡å¯è¯·æ±‚ï¼Œæ”¹ä¸º GET æ–¹æ³•
        reboot_url = f"{COMFYUI_DEFAULT_URL_FOR_WORKFLOW}/api/manager/reboot" # ä½¿ç”¨å¸¸é‡
        response = requests.get(reboot_url)  # æ”¹ä¸º GET è¯·æ±‚
        if response.status_code == 200:
            return "é‡å¯è¯·æ±‚å·²å‘é€ã€‚è¯·ç¨åæ£€æŸ¥ ComfyUI çŠ¶æ€ã€‚"
        else:
            return f"é‡å¯è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
    except Exception as e:
        return f"å‘ç”Ÿé”™è¯¯: {str(e)}"

def trigger_comfyui_interrupt():
    """åŒ…è£…å‡½æ•°ï¼Œç”¨äºä» Gradio è°ƒç”¨ä¸­æ–­åŠŸèƒ½ï¼Œä½¿ç”¨é¢„å®šä¹‰çš„ URL"""
    return cancel_comfyui_task_action(COMFYUI_DEFAULT_URL_FOR_WORKFLOW)

# --- é‡å¯å’Œä¸­æ–­å‡½æ•°ç»“æŸ ---
# handle_interrupt_click å‡½æ•°å°†è¢«ç§»é™¤ï¼Œå› ä¸ºä¸­æ–­æŒ‰é’®è¢«ç§»é™¤ï¼Œå…¶é€»è¾‘å°†æ•´åˆåˆ°æ–°çš„ clear_queue ä¸­


# --- æ—¥å¿—è®°å½•å‡½æ•° ---
def log_message(message):
    timestamp = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%f")[:-3]  # ç²¾ç¡®åˆ°æ¯«ç§’
    print(f"{timestamp} - {message}")

# ä¿®æ”¹å‡½æ•°ä»¥é€šè¿‡ class_type æŸ¥æ‰¾ï¼Œå¹¶é‡å‘½åå‚æ•°
def find_key_by_class_type(prompt, class_type):
    for key, value in prompt.items():
        # ç›´æ¥æ£€æŸ¥ class_type å­—æ®µ
        if isinstance(value, dict) and value.get("class_type") == class_type:
            return key
    return None

def check_seed_node(json_file):
    if not json_file or not os.path.exists(os.path.join(OUTPUT_DIR, json_file)):
        print(f"JSON æ–‡ä»¶æ— æ•ˆæˆ–ä¸å­˜åœ¨: {json_file}")
        return gr.update(visible=False)
    json_path = os.path.join(OUTPUT_DIR, json_file)
    try:
        with open(json_path, "r", encoding="utf-8") as file_json:
            prompt = json.load(file_json)
        # ä½¿ç”¨æ–°çš„å‡½æ•°å’ŒçœŸå®ç±»å
        seed_key = find_key_by_class_type(prompt, "Hua_gradio_Seed")
        return gr.update(visible=seed_key is not None)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"è¯»å–æˆ–è§£æ JSON æ–‡ä»¶æ—¶å‡ºé”™ ({json_file}): {e}")
        return gr.update(visible=False)

current_dir = os.path.dirname(os.path.abspath(__file__))
print("å½“å‰huaæ’ä»¶æ–‡ä»¶çš„ç›®å½•ä¸ºï¼š", current_dir)
parent_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(parent_dir)
try:
    from comfy.cli_args import args
except ImportError:
    print("æ— æ³•å¯¼å…¥ comfy.cli_argsï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™ã€‚")
    args = None # æä¾›ä¸€ä¸ªé»˜è®¤å€¼ä»¥é¿å… NameError

# å°è¯•å¯¼å…¥å›¾æ ‡ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å€¼
try:
    from .node.hua_icons import icons
except ImportError:
    print("æ— æ³•å¯¼å…¥ .hua_iconsï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ†ç±»åç§°ã€‚")
    icons = {"hua_boy_one": "Gradio"} # æä¾›ä¸€ä¸ªé»˜è®¤å€¼

class GradioTextOk:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "string": ("STRING", {"multiline": True, "dynamicPrompts": True, "tooltip": "The text to be encoded."}),
                "name": ("STRING", {"multiline": False, "default": "GradioTextOk", "tooltip": "èŠ‚ç‚¹åç§°"}),
            }
        }
    RETURN_TYPES = ("STRING",)
    FUNCTION = "encode"
    CATEGORY = icons.get("hua_boy_one", "Gradio") # ä½¿ç”¨ get æä¾›é»˜è®¤å€¼
    DESCRIPTION = "Encodes a text prompt..."
    def encode(self, string, name):
        return (string,)

INPUT_DIR = folder_paths.get_input_directory()
OUTPUT_DIR = folder_paths.get_output_directory()
TEMP_DIR = folder_paths.get_temp_directory()

# --- Load Resolution Presets from File ---
# resolution_files and resolution_prefixes are defined here
resolution_files = [
    "Sample_preview/flux_resolution.txt",
    "Sample_preview/sdxl_1_5_resolution.txt"
]
resolution_prefixes = [
    "Flux - ",
    "SDXL - "
]
# load_resolution_presets_from_files is now imported from ui_def
# It needs current_dir (script_dir)
resolution_presets = load_resolution_presets_from_files(resolution_files, resolution_prefixes, current_dir)
# Add a print statement to confirm loading
print(f"Final resolution_presets count (including 'custom'): {len(resolution_presets)}")
if len(resolution_presets) < 10: # Print some examples if loading failed or files are short
    print(f"Example presets: {resolution_presets[:10]}")
# --- End Load Resolution Presets ---


def start_queue(prompt_workflow):
    p = {"prompt": prompt_workflow}
    data = json.dumps(p).encode('utf-8')
    URL = "http://127.0.0.1:8188/prompt"
    max_retries = 5
    retry_delay = 10
    request_timeout = 60

    for attempt in range(max_retries):
        try:
            # ç®€åŒ–æœåŠ¡å™¨æ£€æŸ¥ï¼Œç›´æ¥å°è¯• POST
            response = requests.post(URL, data=data, timeout=request_timeout)
            response.raise_for_status() # å¦‚æœæ˜¯ 4xx æˆ– 5xx ä¼šæŠ›å‡º HTTPError
            print(f"è¯·æ±‚æˆåŠŸ (å°è¯• {attempt + 1}/{max_retries})")
            return True # è¿”å›æˆåŠŸçŠ¶æ€
        except requests.exceptions.HTTPError as http_err: # ç‰¹åˆ«å¤„ç† HTTP é”™è¯¯
            status_code = http_err.response.status_code
            print(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}, HTTP çŠ¶æ€ç : {status_code}): {str(http_err)}")
            if status_code == 400: # Bad Request (ä¾‹å¦‚ invalid prompt)
                print("å‘ç”Ÿ 400 Bad Request é”™è¯¯ï¼Œé€šå¸¸è¡¨ç¤º prompt æ— æ•ˆã€‚åœæ­¢é‡è¯•ã€‚")
                return False # ç«‹åˆ»è¿”å›å¤±è´¥ï¼Œä¸é‡è¯•
            # å¯¹äºå…¶ä»– HTTP é”™è¯¯ (ä¾‹å¦‚ 5xx)ï¼Œç»§ç»­é‡è¯•é€»è¾‘
            if attempt < max_retries - 1:
                print(f"{retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print("è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° (HTTPError)ï¼Œæ”¾å¼ƒè¯·æ±‚ã€‚")
                return False
        except requests.exceptions.RequestException as e: # å…¶ä»–ç½‘ç»œé”™è¯¯ (è¶…æ—¶, è¿æ¥é”™è¯¯ç­‰)
            error_type = type(e).__name__
            print(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}, é”™è¯¯ç±»å‹: {error_type}): {str(e)}")
            if attempt < max_retries - 1:
                print(f"{retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print("è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° (RequestException)ï¼Œæ”¾å¼ƒè¯·æ±‚ã€‚")
                print("å¯èƒ½åŸå› : æœåŠ¡å™¨æœªè¿è¡Œã€ç½‘ç»œé—®é¢˜ã€‚") # ä¿ç•™æ­¤é€šç”¨åŸå› 
                return False # è¿”å›å¤±è´¥çŠ¶æ€
    return False # ç¡®ä¿å‡½æ•°åœ¨æ‰€æœ‰è·¯å¾„éƒ½æœ‰è¿”å›å€¼

def get_json_files():
    try:
        json_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.json') and os.path.isfile(os.path.join(OUTPUT_DIR, f))]
        return json_files
    except FileNotFoundError:
        print(f"è­¦å‘Š: è¾“å‡ºç›®å½• {OUTPUT_DIR} æœªæ‰¾åˆ°ã€‚")
        return []
    except Exception as e:
        print(f"è·å– JSON æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        return []

def refresh_json_files():
    new_choices = get_json_files()
    return gr.update(choices=new_choices)

# strip_prefix, parse_resolution, calculate_aspect_ratio, find_closest_preset are now imported from ui_def

def update_from_preset(resolution_str_with_prefix):
    if resolution_str_with_prefix == "custom":
        # è¿”å›ç©ºæ›´æ–°ï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥
        return "custom", gr.update(), gr.update(), "å½“å‰æ¯”ä¾‹: è‡ªå®šä¹‰"

    # parse_resolution is imported, needs resolution_prefixes
    width, height, ratio, original_str = parse_resolution(resolution_str_with_prefix, resolution_prefixes)

    if width is None: # å¤„ç†æ— æ•ˆæ ¼å¼çš„æƒ…å†µ
        return "custom", gr.update(), gr.update(), "å½“å‰æ¯”ä¾‹: æ— æ•ˆæ ¼å¼"

    # Return the original string with prefix for the dropdown value
    return original_str, width, height, f"å½“å‰æ¯”ä¾‹: {ratio}"

def update_from_inputs(width, height):
    # calculate_aspect_ratio and find_closest_preset are imported
    # find_closest_preset needs resolution_presets and resolution_prefixes
    ratio = calculate_aspect_ratio(width, height)
    closest_preset = find_closest_preset(width, height, resolution_presets, resolution_prefixes)
    return closest_preset, f"å½“å‰æ¯”ä¾‹: {ratio}"

def flip_resolution(width, height):
    if width is None or height is None:
        return None, None
    try:
        # ç¡®ä¿è¿”å›çš„æ˜¯æ•°å­—ç±»å‹
        return int(height), int(width)
    except (ValueError, TypeError):
        return width, height # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸå€¼

# --- æ¨¡å‹åˆ—è¡¨è·å– ---
def get_model_list(model_type):
    try:
        # æ·»åŠ  "None" é€‰é¡¹ï¼Œå…è®¸ä¸é€‰æ‹©
        return ["None"] + folder_paths.get_filename_list(model_type)
    except Exception as e:
        print(f"è·å– {model_type} åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        return ["None"]

lora_list = get_model_list("loras")
checkpoint_list = get_model_list("checkpoints")
unet_list = get_model_list("unet") # å‡è®¾ UNet æ¨¡å‹åœ¨ 'unet' ç›®å½•

# get_output_images is now imported from ui_def

# ä¿®æ”¹ generate_image å‡½æ•°ä»¥æ¥å—åŠ¨æ€ç»„ä»¶åˆ—è¡¨
def generate_image(
    inputimage1, input_video, 
    dynamic_positive_prompts_values: list, # åˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰ positive_prompt_texts çš„å€¼
    prompt_text_negative, 
    json_file, 
    hua_width, hua_height, 
    dynamic_loras_values: list,           # åˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰ lora_dropdowns çš„å€¼
    hua_checkpoint, hua_unet, 
    dynamic_float_nodes_values: list,     # åˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰ float_inputs çš„å€¼
    dynamic_int_nodes_values: list,       # åˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰ int_inputs çš„å€¼
    seed_mode, fixed_seed
):
    global last_used_seed # å£°æ˜ä½¿ç”¨å…¨å±€å˜é‡
    execution_id = str(uuid.uuid4())
    print(f"[{execution_id}] å¼€å§‹ç”Ÿæˆä»»åŠ¡ (ç§å­æ¨¡å¼: {seed_mode})...")
    output_type = None # 'image' or 'video'

    if not json_file:
        print(f"[{execution_id}] é”™è¯¯: æœªé€‰æ‹©å·¥ä½œæµ JSON æ–‡ä»¶ã€‚")
        return None, None # è¿”å› (None, None) è¡¨ç¤ºå¤±è´¥

    json_path = os.path.join(OUTPUT_DIR, json_file)
    if not os.path.exists(json_path):
        print(f"[{execution_id}] é”™è¯¯: å·¥ä½œæµ JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        return None, None

    try:
        with open(json_path, "r", encoding="utf-8") as file_json:
            prompt = json.load(file_json)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"[{execution_id}] è¯»å–æˆ–è§£æ JSON æ–‡ä»¶æ—¶å‡ºé”™ ({json_path}): {e}")
        return None, None

    # --- æ›´æ–° Prompt ---
    # é¦–å…ˆè·å–å·¥ä½œæµä¸­å®é™…å­˜åœ¨çš„åŠ¨æ€èŠ‚ç‚¹çš„å®šä¹‰
    # æ³¨æ„ï¼šget_workflow_defaults_and_visibility ç°åœ¨è¿”å›æ›´è¯¦ç»†çš„åŠ¨æ€ç»„ä»¶ä¿¡æ¯
    # æˆ‘ä»¬éœ€è¦ä» prompt (åŸå§‹JSON) ä¸­ç›´æ¥æŸ¥æ‰¾èŠ‚ç‚¹IDï¼Œæˆ–è€…ä¾èµ– get_workflow_defaults_and_visibility è¿”å›çš„ID
    # ä¸ºç®€åŒ–ï¼Œè¿™é‡Œå‡è®¾ get_workflow_defaults_and_visibility è¿”å›çš„ dynamic_components åŒ…å«èŠ‚ç‚¹ID
    # å¹¶ä¸” dynamic_*_values åˆ—è¡¨ä¸­çš„é¡ºåºä¸ get_workflow_defaults_and_visibility æ‰¾åˆ°çš„èŠ‚ç‚¹é¡ºåºä¸€è‡´

    workflow_info = get_workflow_defaults_and_visibility(json_file, OUTPUT_DIR, resolution_prefixes, resolution_presets, MAX_DYNAMIC_COMPONENTS)
    
    # --- å•ä¾‹èŠ‚ç‚¹æŸ¥æ‰¾ ---
    image_input_key = find_key_by_class_type(prompt, "GradioInputImage")
    video_input_key = find_key_by_class_type(prompt, "VHS_LoadVideo")
    seed_key = find_key_by_class_type(prompt, "Hua_gradio_Seed")
    text_bad_key = find_key_by_class_type(prompt, "GradioTextBad")
    fenbianlv_key = find_key_by_class_type(prompt, "Hua_gradio_resolution")
    checkpoint_key = find_key_by_class_type(prompt, "Hua_CheckpointLoaderSimple")
    unet_key = find_key_by_class_type(prompt, "Hua_UNETLoader") # ç¡®ä¿ç±»åæ­£ç¡®
    hua_output_key = find_key_by_class_type(prompt, "Hua_Output")
    hua_video_output_key = find_key_by_class_type(prompt, "Hua_Video_Output")
    
    inputfilename = None # åˆå§‹åŒ–
    if image_input_key:
        if inputimage1 is not None:
            try:
                # ç¡®ä¿ inputimage1 æ˜¯ PIL Image å¯¹è±¡
                if isinstance(inputimage1, np.ndarray):
                    img = Image.fromarray(inputimage1)
                elif isinstance(inputimage1, Image.Image):
                    img = inputimage1
                else:
                    print(f"[{execution_id}] è­¦å‘Š: æœªçŸ¥çš„è¾“å…¥å›¾åƒç±»å‹: {type(inputimage1)}ã€‚å°è¯•è·³è¿‡å›¾åƒè¾“å…¥ã€‚")
                    img = None

                if img:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    inputfilename = f"gradio_input_{timestamp}_{random.randint(100, 999)}.png"
                    save_path = os.path.join(INPUT_DIR, inputfilename)
                    img.save(save_path)
                    prompt[image_input_key]["inputs"]["image"] = inputfilename
                    print(f"[{execution_id}] è¾“å…¥å›¾åƒå·²ä¿å­˜åˆ°: {save_path}")
            except Exception as e:
                print(f"[{execution_id}] ä¿å­˜è¾“å…¥å›¾åƒæ—¶å‡ºé”™: {e}")
                # ä¸è®¾ç½®å›¾åƒè¾“å…¥ï¼Œè®©å·¥ä½œæµä½¿ç”¨é»˜è®¤å€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "image" in prompt[image_input_key]["inputs"]:
                    del prompt[image_input_key]["inputs"]["image"] # æˆ–è€…è®¾ç½®ä¸º Noneï¼Œå–å†³äºèŠ‚ç‚¹å¦‚ä½•å¤„ç†
        else:
             # å¦‚æœæ²¡æœ‰è¾“å…¥å›¾åƒï¼Œç¡®ä¿èŠ‚ç‚¹è¾“å…¥ä¸­æ²¡æœ‰æ®‹ç•™çš„æ–‡ä»¶å
             if image_input_key and "image" in prompt.get(image_input_key, {}).get("inputs", {}):
                 # å°è¯•ç§»é™¤æˆ–è®¾ç½®ä¸ºç©ºï¼Œå–å†³äºèŠ‚ç‚¹æœŸæœ›
                 # prompt[image_input_key]["inputs"]["image"] = None
                 print(f"[{execution_id}] æ— è¾“å…¥å›¾åƒæä¾›ï¼Œæ¸…é™¤èŠ‚ç‚¹ {image_input_key} çš„ image è¾“å…¥ã€‚")
                 # æˆ–è€…å¦‚æœèŠ‚ç‚¹å¿…é¡»æœ‰è¾“å…¥ï¼Œåˆ™å¯èƒ½éœ€è¦æŠ¥é”™æˆ–ä½¿ç”¨é»˜è®¤å›¾åƒ
                 # return None, None # å¦‚æœå›¾ç”Ÿå›¾èŠ‚ç‚¹å¿…é¡»æœ‰è¾“å…¥

    # --- å¤„ç†è§†é¢‘è¾“å…¥ ---
    inputvideofilename = None
    if video_input_key:
        if input_video is not None and os.path.exists(input_video):
            try:
                # Gradio è¿”å›çš„æ˜¯ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼Œéœ€è¦å¤åˆ¶åˆ° ComfyUI çš„ input ç›®å½•
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                # ä¿ç•™åŸå§‹æ‰©å±•å
                original_ext = os.path.splitext(input_video)[1]
                inputvideofilename = f"gradio_input_{timestamp}_{random.randint(100, 999)}{original_ext}"
                dest_path = os.path.join(INPUT_DIR, inputvideofilename)
                shutil.copy2(input_video, dest_path) # ä½¿ç”¨ copy2 ä¿ç•™å…ƒæ•°æ®
                prompt[video_input_key]["inputs"]["video"] = inputvideofilename
                print(f"[{execution_id}] è¾“å…¥è§†é¢‘å·²å¤åˆ¶åˆ°: {dest_path}")
            except Exception as e:
                print(f"[{execution_id}] å¤åˆ¶è¾“å…¥è§†é¢‘æ—¶å‡ºé”™: {e}")
                # æ¸…é™¤èŠ‚ç‚¹è¾“å…¥ï¼Œè®©å…¶ä½¿ç”¨é»˜è®¤å€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "video" in prompt[video_input_key]["inputs"]:
                    del prompt[video_input_key]["inputs"]["video"]
        else:
            # å¦‚æœæ²¡æœ‰è¾“å…¥è§†é¢‘æˆ–è·¯å¾„æ— æ•ˆï¼Œç¡®ä¿èŠ‚ç‚¹è¾“å…¥ä¸­æ²¡æœ‰æ®‹ç•™çš„æ–‡ä»¶å
            if "video" in prompt.get(video_input_key, {}).get("inputs", {}):
                print(f"[{execution_id}] æ— æœ‰æ•ˆè¾“å…¥è§†é¢‘æä¾›ï¼Œæ¸…é™¤èŠ‚ç‚¹ {video_input_key} çš„ video è¾“å…¥ã€‚")
                # ç§»é™¤æˆ–è®¾ç½®ä¸ºç©ºï¼Œå–å†³äºèŠ‚ç‚¹æœŸæœ›
                 # prompt[video_input_key]["inputs"]["video"] = None

    if seed_key:
        with seed_lock: # ä¿æŠ¤å¯¹ last_used_seed çš„è®¿é—®
            current_seed = 0
            if seed_mode == "éšæœº":
                current_seed = random.randint(0, 0xffffffff)
                print(f"[{execution_id}] ç§å­æ¨¡å¼: éšæœº. ç”Ÿæˆç§å­: {current_seed}")
            elif seed_mode == "é€’å¢":
                if last_used_seed == -1: # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œé€’å¢
                    last_used_seed = random.randint(0, 0xffffffff -1) # éšæœºé€‰ä¸€ä¸ªåˆå§‹å€¼ï¼Œé¿å…æ€»æ˜¯ä»0å¼€å§‹ä¸”ç¡®ä¿èƒ½+1
                last_used_seed = (last_used_seed + 1) & 0xffffffff # é€’å¢å¹¶å¤„ç†æº¢å‡º (æŒ‰ä½ä¸)
                current_seed = last_used_seed
                print(f"[{execution_id}] ç§å­æ¨¡å¼: é€’å¢. ä½¿ç”¨ç§å­: {current_seed}")
            elif seed_mode == "é€’å‡":
                if last_used_seed == -1: # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œé€’å‡
                    last_used_seed = random.randint(1, 0xffffffff) # éšæœºé€‰ä¸€ä¸ªåˆå§‹å€¼ï¼Œé¿å…æ€»æ˜¯ä»0å¼€å§‹ä¸”ç¡®ä¿èƒ½-1
                last_used_seed = (last_used_seed - 1) & 0xffffffff # é€’å‡å¹¶å¤„ç†ä¸‹æº¢ (æŒ‰ä½ä¸)
                current_seed = last_used_seed
                print(f"[{execution_id}] ç§å­æ¨¡å¼: é€’å‡. ä½¿ç”¨ç§å­: {current_seed}")
            elif seed_mode == "å›ºå®š":
                try:
                    current_seed = int(fixed_seed) & 0xffffffff # ç¡®ä¿æ˜¯æ•´æ•°ä¸”åœ¨èŒƒå›´å†…
                    last_used_seed = current_seed # å›ºå®šæ¨¡å¼ä¹Ÿæ›´æ–° last_used_seed
                    print(f"[{execution_id}] ç§å­æ¨¡å¼: å›ºå®š. ä½¿ç”¨ç§å­: {current_seed}")
                except (ValueError, TypeError):
                    current_seed = random.randint(0, 0xffffffff)
                    last_used_seed = current_seed
                    print(f"[{execution_id}] ç§å­æ¨¡å¼: å›ºå®š. å›ºå®šç§å­å€¼æ— æ•ˆ ('{fixed_seed}')ï¼Œå›é€€åˆ°éšæœºç§å­: {current_seed}")
            else: # æœªçŸ¥æ¨¡å¼ï¼Œé»˜è®¤ä¸ºéšæœº
                current_seed = random.randint(0, 0xffffffff)
                last_used_seed = current_seed
                print(f"[{execution_id}] æœªçŸ¥ç§å­æ¨¡å¼ '{seed_mode}'. å›é€€åˆ°éšæœºç§å­: {current_seed}")

            prompt[seed_key]["inputs"]["seed"] = current_seed
    
    # æ›´æ–°åŠ¨æ€æ­£å‘æç¤ºè¯
    actual_positive_prompt_nodes = workflow_info["dynamic_components"]["GradioTextOk"]
    for i, node_info in enumerate(actual_positive_prompt_nodes):
        if i < len(dynamic_positive_prompts_values):
            node_id_to_update = node_info["id"]
            if node_id_to_update in prompt:
                prompt[node_id_to_update]["inputs"]["string"] = dynamic_positive_prompts_values[i]
                print(f"[{execution_id}] æ›´æ–°æ­£å‘æç¤ºèŠ‚ç‚¹ {node_id_to_update} (UIç»„ä»¶ {i+1}) ä¸º: '{dynamic_positive_prompts_values[i]}'")
            else:
                print(f"[{execution_id}] è­¦å‘Š: æœªåœ¨promptä¸­æ‰¾åˆ°æ­£å‘æç¤ºèŠ‚ç‚¹ID {node_id_to_update}")
        else:
            # é€šå¸¸ä¸åº”å‘ç”Ÿï¼Œå› ä¸º dynamic_positive_prompts_values åº”è¯¥ä¸å¯è§ç»„ä»¶æ•°é‡åŒ¹é…
            print(f"[{execution_id}] è­¦å‘Š: æ­£å‘æç¤ºå€¼åˆ—è¡¨é•¿åº¦ä¸è¶³ä»¥è¦†ç›–èŠ‚ç‚¹ {node_info['id']}")


    if text_bad_key: prompt[text_bad_key]["inputs"]["string"] = prompt_text_negative

    if fenbianlv_key:
        try:
            width_val = int(hua_width)
            height_val = int(hua_height)
            prompt[fenbianlv_key]["inputs"]["custom_width"] = width_val
            prompt[fenbianlv_key]["inputs"]["custom_height"] = height_val
            print(f"[{execution_id}] è®¾ç½®åˆ†è¾¨ç‡: {width_val}x{height_val}")
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print(f"[{execution_id}] åˆ†è¾¨ç‡èŠ‚ç‚¹ID: {fenbianlv_key}")
            print(f"[{execution_id}] åˆ†è¾¨ç‡èŠ‚ç‚¹è¾“å…¥: {prompt[fenbianlv_key]['inputs']}")
        except (ValueError, TypeError, KeyError) as e:
             print(f"[{execution_id}] æ›´æ–°åˆ†è¾¨ç‡æ—¶å‡ºé”™: {e}. ä½¿ç”¨é»˜è®¤å€¼æˆ–è·³è¿‡ã€‚")
             # æ‰“å°å½“å‰promptç»“æ„å¸®åŠ©è°ƒè¯•
             print(f"[{execution_id}] å½“å‰promptç»“æ„: {json.dumps(prompt, indent=2, ensure_ascii=False)}")

    # æ›´æ–°åŠ¨æ€Loraæ¨¡å‹é€‰æ‹©
    actual_lora_nodes = workflow_info["dynamic_components"]["Hua_LoraLoaderModelOnly"]
    for i, node_info in enumerate(actual_lora_nodes):
        if i < len(dynamic_loras_values):
            node_id_to_update = node_info["id"]
            lora_name_from_ui = dynamic_loras_values[i]
            if node_id_to_update in prompt and lora_name_from_ui != "None":
                prompt[node_id_to_update]["inputs"]["lora_name"] = lora_name_from_ui
                print(f"[{execution_id}] æ›´æ–°LoraèŠ‚ç‚¹ {node_id_to_update} (UIç»„ä»¶ {i+1}) ä¸º: '{lora_name_from_ui}'")
            elif lora_name_from_ui == "None":
                 print(f"[{execution_id}] LoraèŠ‚ç‚¹ {node_id_to_update} (UIç»„ä»¶ {i+1}) é€‰æ‹©ä¸º 'None'ï¼Œä¸æ›´æ–°ã€‚")
            else:
                print(f"[{execution_id}] è­¦å‘Š: æœªåœ¨promptä¸­æ‰¾åˆ°LoraèŠ‚ç‚¹ID {node_id_to_update}")

    if checkpoint_key and hua_checkpoint != "None": prompt[checkpoint_key]["inputs"]["ckpt_name"] = hua_checkpoint
    if unet_key and hua_unet != "None": prompt[unet_key]["inputs"]["unet_name"] = hua_unet

    # æ›´æ–°åŠ¨æ€IntèŠ‚ç‚¹è¾“å…¥
    actual_int_nodes = workflow_info["dynamic_components"]["HuaIntNode"]
    for i, node_info in enumerate(actual_int_nodes):
        if i < len(dynamic_int_nodes_values):
            node_id_to_update = node_info["id"]
            int_value_from_ui = dynamic_int_nodes_values[i]
            if node_id_to_update in prompt and int_value_from_ui is not None:
                try:
                    prompt[node_id_to_update]["inputs"]["int_value"] = int(int_value_from_ui)
                    print(f"[{execution_id}] æ›´æ–°IntèŠ‚ç‚¹ {node_id_to_update} (UIç»„ä»¶ {i+1}) ä¸º: {int(int_value_from_ui)}")
                except (ValueError, TypeError, KeyError) as e:
                    print(f"[{execution_id}] æ›´æ–°IntèŠ‚ç‚¹ {node_id_to_update} æ—¶å‡ºé”™: {e}. ä½¿ç”¨é»˜è®¤å€¼æˆ–è·³è¿‡ã€‚")
            else:
                 print(f"[{execution_id}] è­¦å‘Š: æœªåœ¨promptä¸­æ‰¾åˆ°IntèŠ‚ç‚¹ID {node_id_to_update} æˆ–å€¼ä¸ºNone")
    
    # æ›´æ–°åŠ¨æ€FloatèŠ‚ç‚¹è¾“å…¥
    actual_float_nodes = workflow_info["dynamic_components"]["HuaFloatNode"]
    for i, node_info in enumerate(actual_float_nodes):
        if i < len(dynamic_float_nodes_values):
            node_id_to_update = node_info["id"]
            float_value_from_ui = dynamic_float_nodes_values[i]
            if node_id_to_update in prompt and float_value_from_ui is not None:
                try:
                    prompt[node_id_to_update]["inputs"]["float_value"] = float(float_value_from_ui)
                    print(f"[{execution_id}] æ›´æ–°FloatèŠ‚ç‚¹ {node_id_to_update} (UIç»„ä»¶ {i+1}) ä¸º: {float(float_value_from_ui)}")
                except (ValueError, TypeError, KeyError) as e:
                    print(f"[{execution_id}] æ›´æ–°FloatèŠ‚ç‚¹ {node_id_to_update} æ—¶å‡ºé”™: {e}. ä½¿ç”¨é»˜è®¤å€¼æˆ–è·³è¿‡ã€‚")
            else:
                print(f"[{execution_id}] è­¦å‘Š: æœªåœ¨promptä¸­æ‰¾åˆ°FloatèŠ‚ç‚¹ID {node_id_to_update} æˆ–å€¼ä¸ºNone")

    # --- è®¾ç½®è¾“å‡ºèŠ‚ç‚¹çš„ unique_id ---
    if hua_output_key:
        prompt[hua_output_key]["inputs"]["unique_id"] = execution_id
        output_type = 'image'
        print(f"[{execution_id}] å·²å°† unique_id è®¾ç½®ç»™å›¾ç‰‡è¾“å‡ºèŠ‚ç‚¹ {hua_output_key}")
    elif hua_video_output_key:
        prompt[hua_video_output_key]["inputs"]["unique_id"] = execution_id
        output_type = 'video'
        print(f"[{execution_id}] å·²å°† unique_id è®¾ç½®ç»™è§†é¢‘è¾“å‡ºèŠ‚ç‚¹ {hua_video_output_key}")
    else:
        print(f"[{execution_id}] è­¦å‘Š: æœªæ‰¾åˆ° 'ğŸŒ™å›¾åƒè¾“å‡ºåˆ°gradioå‰ç«¯' æˆ– 'ğŸ¬è§†é¢‘è¾“å‡ºåˆ°gradioå‰ç«¯' èŠ‚ç‚¹ï¼Œå¯èƒ½æ— æ³•è·å–ç»“æœã€‚")
        return None, None # å¦‚æœå¿…é¡»æœ‰è¾“å‡ºèŠ‚ç‚¹æ‰èƒ½å·¥ä½œï¼Œåˆ™è¿”å›å¤±è´¥

    # --- å‘é€è¯·æ±‚å¹¶ç­‰å¾…ç»“æœ ---
    try:
        print(f"[{execution_id}] è°ƒç”¨ start_queue å‘é€è¯·æ±‚...")
        success = start_queue(prompt) # å‘é€è¯·æ±‚åˆ° ComfyUI
        if not success:
             print(f"[{execution_id}] è¯·æ±‚å‘é€å¤±è´¥ (start_queue returned False). ComfyUIåç«¯æ‹’ç»äº†ä»»åŠ¡æˆ–å‘ç”Ÿé”™è¯¯ã€‚")
             return "COMFYUI_REJECTED", None # ç‰¹æ®Šè¿”å›å€¼è¡¨ç¤ºåç«¯æ‹’ç»
        print(f"[{execution_id}] è¯·æ±‚å·²å‘é€ï¼Œå¼€å§‹ç­‰å¾…ç»“æœ...")
    except Exception as e:
        print(f"[{execution_id}] è°ƒç”¨ start_queue æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        return None, None

    # --- ç²¾ç¡®æ–‡ä»¶è·å–é€»è¾‘ ---
    temp_file_path = os.path.join(TEMP_DIR, f"{execution_id}.json")
    # å¢åŠ æ—¥å¿—ï¼Œæ‰“å° TEMP_DIR çš„å®é™…è·¯å¾„
    log_message(f"[{execution_id}] TEMP_DIR is: {TEMP_DIR}")
    log_message(f"[{execution_id}] å¼€å§‹ç­‰å¾…ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")

    start_time = time.time()
    wait_timeout = 1000 # ä¿æŒåŸæ¥çš„è¶…æ—¶
    check_interval = 1
    files_in_temp_dir_logged = False # æ ‡å¿—ä½ï¼Œç¡®ä¿åªè®°å½•ä¸€æ¬¡ç›®å½•å†…å®¹

    while time.time() - start_time < wait_timeout:
        if os.path.exists(temp_file_path):
            log_message(f"[{execution_id}] æ£€æµ‹åˆ°ä¸´æ—¶æ–‡ä»¶ (è€—æ—¶: {time.time() - start_time:.1f}ç§’)")
            try:
                log_message(f"[{execution_id}] Waiting briefly before reading {temp_file_path}...") # ä½¿ç”¨ log_message
                time.sleep(1.0) # å¢åŠ ç­‰å¾…æ—¶é—´åˆ° 1 ç§’

                with open(temp_file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if not content:
                        log_message(f"[{execution_id}] è­¦å‘Š: ä¸´æ—¶æ–‡ä»¶ä¸ºç©ºã€‚") # ä½¿ç”¨ log_message
                        time.sleep(check_interval)
                        continue
                    log_message(f"[{execution_id}] Read content: '{content[:200]}...'") # ä½¿ç”¨ log_message

                output_paths_data = json.loads(content)
                log_message(f"[{execution_id}] Parsed JSON data type: {type(output_paths_data)}") # ä½¿ç”¨ log_message

                # --- æ£€æŸ¥é”™è¯¯ç»“æ„ ---
                if isinstance(output_paths_data, dict) and "error" in output_paths_data:
                    error_message = output_paths_data.get("error", "Unknown error from node.")
                    generated_files = output_paths_data.get("generated_files", [])
                    log_message(f"[{execution_id}] é”™è¯¯: èŠ‚ç‚¹è¿”å›é”™è¯¯: {error_message}. æ–‡ä»¶åˆ—è¡¨ (å¯èƒ½ä¸å®Œæ•´): {generated_files}") # ä½¿ç”¨ log_message
                    try:
                        os.remove(temp_file_path)
                        log_message(f"[{execution_id}] å·²åˆ é™¤åŒ…å«é”™è¯¯çš„ä¸´æ—¶æ–‡ä»¶ã€‚") # ä½¿ç”¨ log_message
                    except OSError as e:
                        log_message(f"[{execution_id}] åˆ é™¤åŒ…å«é”™è¯¯çš„ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}") # ä½¿ç”¨ log_message
                    return None, None # è¿”å›å¤±è´¥

                # --- æå–è·¯å¾„åˆ—è¡¨ ---
                output_paths = []
                if isinstance(output_paths_data, dict) and "generated_files" in output_paths_data:
                    output_paths = output_paths_data["generated_files"]
                    log_message(f"[{execution_id}] Extracted 'generated_files': {output_paths} (Count: {len(output_paths)})") # ä½¿ç”¨ log_message
                elif isinstance(output_paths_data, list): # å¤„ç†æ—§æ ¼å¼ä»¥é˜²ä¸‡ä¸€
                     output_paths = output_paths_data
                     log_message(f"[{execution_id}] Parsed JSON directly as list: {output_paths} (Count: {len(output_paths)})") # ä½¿ç”¨ log_message
                else:
                    log_message(f"[{execution_id}] é”™è¯¯: æ— æ³•è¯†åˆ«çš„ JSON ç»“æ„ã€‚") # ä½¿ç”¨ log_message
                    try: os.remove(temp_file_path)
                    except OSError: pass
                    return None, None # æ— æ³•è¯†åˆ«çš„ç»“æ„

                # --- è¯¦ç»†éªŒè¯è·¯å¾„ ---
                log_message(f"[{execution_id}] Starting path validation for {len(output_paths)} paths...") # ä½¿ç”¨ log_message
                valid_paths = []
                invalid_paths = []
                for i, p in enumerate(output_paths):
                    abs_p = os.path.abspath(p)
                    exists = os.path.exists(abs_p)
                    log_message(f"[{execution_id}] Validating path {i+1}/{len(output_paths)}: '{p}' -> Absolute: '{abs_p}' -> Exists: {exists}") # ä½¿ç”¨ log_message
                    if exists:
                        valid_paths.append(abs_p)
                    else:
                        invalid_paths.append(p)

                log_message(f"[{execution_id}] Validation complete. Valid: {len(valid_paths)}, Invalid: {len(invalid_paths)}") # ä½¿ç”¨ log_message

                try:
                    os.remove(temp_file_path)
                    log_message(f"[{execution_id}] å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶ã€‚") # ä½¿ç”¨ log_message
                except OSError as e:
                    log_message(f"[{execution_id}] åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}") # ä½¿ç”¨ log_message

                if not valid_paths:
                    log_message(f"[{execution_id}] é”™è¯¯: æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚Invalid paths were: {invalid_paths}") # ä½¿ç”¨ log_message
                    return None, None

                first_valid_path = valid_paths[0]
                if first_valid_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.webp', '.bmp')):
                    determined_output_type = 'image'
                elif first_valid_path.lower().endswith(('.mp4', '.webm', '.avi', '.mov', '.mkv')):
                    determined_output_type = 'video'
                else:
                    log_message(f"[{execution_id}] è­¦å‘Š: æœªçŸ¥çš„æ–‡ä»¶ç±»å‹: {first_valid_path}ã€‚é»˜è®¤ä¸ºå›¾ç‰‡ã€‚") # ä½¿ç”¨ log_message
                    determined_output_type = 'image'

                if output_type and determined_output_type != output_type:
                     log_message(f"[{execution_id}] è­¦å‘Š: å·¥ä½œæµè¾“å‡ºèŠ‚ç‚¹ç±»å‹ ({output_type}) ä¸å®é™…æ–‡ä»¶ç±»å‹ ({determined_output_type}) ä¸åŒ¹é…ã€‚") # ä½¿ç”¨ log_message

                log_message(f"[{execution_id}] ä»»åŠ¡æˆåŠŸå®Œæˆï¼Œè¿”å›ç±»å‹ '{determined_output_type}' å’Œ {len(valid_paths)} ä¸ªæœ‰æ•ˆè·¯å¾„ã€‚") # ä½¿ç”¨ log_message
                return determined_output_type, valid_paths

            except json.JSONDecodeError as e:
                log_message(f"[{execution_id}] è¯»å–æˆ–è§£æä¸´æ—¶æ–‡ä»¶ JSON å¤±è´¥: {e}. æ–‡ä»¶å†…å®¹: '{content[:100]}...'") # ä½¿ç”¨ log_message
                time.sleep(check_interval * 2)
            except Exception as e:
                log_message(f"[{execution_id}] å¤„ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}") # ä½¿ç”¨ log_message
                try: os.remove(temp_file_path)
                except OSError: pass
                return None, None

        # å¦‚æœç­‰å¾…è¶…è¿‡ N ç§’ä»æœªæ‰¾åˆ°æ–‡ä»¶ï¼Œè®°å½•ä¸€ä¸‹ TEMP_DIR çš„å†…å®¹ï¼Œå¸®åŠ©è°ƒè¯•
        if not files_in_temp_dir_logged and (time.time() - start_time) > 5: # ä¾‹å¦‚ç­‰å¾…5ç§’å
            try:
                temp_dir_contents = os.listdir(TEMP_DIR)
                log_message(f"[{execution_id}] ç­‰å¾…è¶…è¿‡5ç§’ï¼ŒTEMP_DIR ('{TEMP_DIR}') å†…å®¹: {temp_dir_contents}")
            except Exception as e_dir:
                log_message(f"[{execution_id}] æ— æ³•åˆ—å‡º TEMP_DIR å†…å®¹: {e_dir}")
            files_in_temp_dir_logged = True # é¿å…é‡å¤è®°å½•

        time.sleep(check_interval)

    # è¶…æ—¶å¤„ç†
    log_message(f"[{execution_id}] ç­‰å¾…ä¸´æ—¶æ–‡ä»¶è¶…æ—¶ ({wait_timeout}ç§’)ã€‚TEMP_DIR ('{TEMP_DIR}') æœ€ç»ˆå†…å®¹å¯èƒ½å·²åœ¨ä¸Šé¢è®°å½•ã€‚") # ä½¿ç”¨ log_message
    return None, None # è¶…æ—¶ï¼Œè¿”å› None

# fuck and get_workflow_defaults_and_visibility are now imported from ui_def.
# The helper find_key_by_class_type_internal was moved to ui_def.py as it's used by them.

# --- é˜Ÿåˆ—å¤„ç†å‡½æ•° (æ›´æ–°ç­¾åä»¥åŒ…å«åŠ¨æ€ç»„ä»¶åˆ—è¡¨) ---
def run_queued_tasks(
    inputimage1, input_video, 
    # Capture all dynamic positive prompts using *args or by naming them if MAX_DYNAMIC_COMPONENTS is fixed
    # Assuming run_button.click inputs are: input_image, input_video, *positive_prompt_texts, prompt_negative, ...
    # So, we need to capture these based on MAX_DYNAMIC_COMPONENTS
    # Let's define them explicitly for clarity up to MAX_DYNAMIC_COMPONENTS
    # This requires knowing the exact order from run_button.click
    # The order in run_button.click is:
    # input_image, input_video, 
    # *positive_prompt_texts, (size MAX_DYNAMIC_COMPONENTS)
    # prompt_negative, 
    # json_dropdown, hua_width, hua_height, 
    # *lora_dropdowns, (size MAX_DYNAMIC_COMPONENTS)
    # hua_checkpoint_dropdown, hua_unet_dropdown, 
    # *float_inputs, (size MAX_DYNAMIC_COMPONENTS)
    # *int_inputs, (size MAX_DYNAMIC_COMPONENTS)
    # seed_mode_dropdown, fixed_seed_input,
    # queue_count

    # We'll use *args and slicing for dynamic parts if function signature becomes too long,
    # or list them all if MAX_DYNAMIC_COMPONENTS is small and fixed.
    # For now, let's assume they are passed positionally and we'll reconstruct lists.
    # This is tricky. A better way is to pass *args to run_queued_tasks and then unpack.
    # Or, more simply, modify run_button.click to pass lists directly if Gradio allows.
    # Since Gradio passes them as individual args, we must list them or use *args.
    
    # Let's list them out based on run_button.click inputs:
    dynamic_prompt_1, dynamic_prompt_2, dynamic_prompt_3, dynamic_prompt_4, dynamic_prompt_5, # From *positive_prompt_texts
    prompt_text_negative, 
    json_file, 
    hua_width, hua_height, 
    dynamic_lora_1, dynamic_lora_2, dynamic_lora_3, dynamic_lora_4, dynamic_lora_5,       # From *lora_dropdowns
    hua_checkpoint, hua_unet, 
    dynamic_float_1, dynamic_float_2, dynamic_float_3, dynamic_float_4, dynamic_float_5, # From *float_inputs
    dynamic_int_1, dynamic_int_2, dynamic_int_3, dynamic_int_4, dynamic_int_5,         # From *int_inputs
    seed_mode, fixed_seed, 
    queue_count=1, progress=gr.Progress(track_tqdm=True)
):
    global accumulated_image_results, last_video_result, executor

    # Reconstruct lists for dynamic components
    dynamic_positive_prompts_values = [dynamic_prompt_1, dynamic_prompt_2, dynamic_prompt_3, dynamic_prompt_4, dynamic_prompt_5]
    dynamic_loras_values = [dynamic_lora_1, dynamic_lora_2, dynamic_lora_3, dynamic_lora_4, dynamic_lora_5]
    dynamic_float_nodes_values = [dynamic_float_1, dynamic_float_2, dynamic_float_3, dynamic_float_4, dynamic_float_5]
    dynamic_int_nodes_values = [dynamic_int_1, dynamic_int_2, dynamic_int_3, dynamic_int_4, dynamic_int_5]

    current_batch_image_results = []

    # 1. å°†æ–°ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
    if queue_count > 1:
        with results_lock:
            accumulated_image_results = []
            current_batch_image_results = []
            last_video_result = None # æ‰¹é‡ä»»åŠ¡å¼€å§‹æ—¶æ¸…é™¤æ—§è§†é¢‘
    elif queue_count == 1:
         # å•ä»»åŠ¡æ¨¡å¼ï¼Œæ¸…é™¤æ—§è§†é¢‘ç»“æœï¼Œå›¾ç‰‡ç»“æœå°†åœ¨æˆåŠŸåç›´æ¥æ›¿æ¢
         with results_lock:
             last_video_result = None

    # å°†æ‰€æœ‰å‚æ•°æ‰“åŒ…åˆ° task_params_tuple for generate_image
    task_params_tuple = (
        inputimage1, input_video,
        dynamic_positive_prompts_values, # Pass the list
        prompt_text_negative,
        json_file,
        hua_width, hua_height,
        dynamic_loras_values,            # Pass the list
        hua_checkpoint, hua_unet,
        dynamic_float_nodes_values,      # Pass the list
        dynamic_int_nodes_values,        # Pass the list
        seed_mode, fixed_seed
    )
    log_message(f"[QUEUE_DEBUG] æ¥æ”¶åˆ°æ–°ä»»åŠ¡è¯·æ±‚ (ç§å­æ¨¡å¼: {seed_mode})ã€‚å½“å‰é˜Ÿåˆ—é•¿åº¦ (åŠ é”å‰): {len(task_queue)}")
    with queue_lock:
        for _ in range(max(1, int(queue_count))):
            task_queue.append(task_params_tuple) 
        current_queue_size = len(task_queue)
        log_message(f"[QUEUE_DEBUG] å·²æ·»åŠ  {queue_count} ä¸ªä»»åŠ¡åˆ°é˜Ÿåˆ—ã€‚å½“å‰é˜Ÿåˆ—é•¿åº¦ (åŠ é”å): {current_queue_size}")
    log_message(f"[QUEUE_DEBUG] ä»»åŠ¡æ·»åŠ å®Œæˆï¼Œé‡Šæ”¾é”ã€‚")

    # åˆå§‹çŠ¶æ€æ›´æ–°ï¼šæ˜¾ç¤ºå½“å‰ç´¯ç§¯ç»“æœå’Œé˜Ÿåˆ—ä¿¡æ¯
    # Default to results tab initially
    initial_updates = {
        queue_status_display: gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: {'æ˜¯' if processing_event.is_set() else 'å¦'}"),
        main_output_tabs_component: gr.Tabs(selected="tab_generate_result") # Default to results tab
    }
    with results_lock:
        initial_updates[output_gallery] = gr.update(value=accumulated_image_results[:])
        initial_updates[output_video] = gr.update(value=last_video_result)

    log_message(f"[QUEUE_DEBUG] å‡†å¤‡ yield åˆå§‹çŠ¶æ€æ›´æ–°ã€‚é˜Ÿåˆ—: {current_queue_size}, å¤„ç†ä¸­: {processing_event.is_set()}")
    yield initial_updates
    log_message(f"[QUEUE_DEBUG] å·² yield åˆå§‹çŠ¶æ€æ›´æ–°ã€‚")

    # 2. æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿›ç¨‹åœ¨å¤„ç†é˜Ÿåˆ—
    log_message(f"[QUEUE_DEBUG] æ£€æŸ¥å¤„ç†çŠ¶æ€: processing_event.is_set() = {processing_event.is_set()}")
    if processing_event.is_set():
        log_message("[QUEUE_DEBUG] å·²æœ‰ä»»åŠ¡åœ¨å¤„ç†é˜Ÿåˆ—ï¼Œæ–°ä»»åŠ¡å·²æ’é˜Ÿã€‚å‡½æ•°è¿”å›ã€‚")
        return

    # 3. å¼€å§‹å¤„ç†é˜Ÿåˆ—
    log_message(f"[QUEUE_DEBUG] æ²¡æœ‰ä»»åŠ¡åœ¨å¤„ç†ï¼Œå‡†å¤‡è®¾ç½® processing_event ä¸º Trueã€‚")
    processing_event.set()
    log_message(f"[QUEUE_DEBUG] processing_event å·²è®¾ç½®ä¸º Trueã€‚å¼€å§‹å¤„ç†å¾ªç¯ã€‚")

    def process_task(task_params):
        try:
            output_type, new_paths = generate_image(*task_params)
            return output_type, new_paths
        except Exception as e:
            log_message(f"[QUEUE_DEBUG] Exception in process_task: {e}")
            return None, None

    try:
        log_message("[QUEUE_DEBUG] Entering main processing loop (while True).")
        while True:
            task_to_run = None
            current_queue_size = 0
            log_message("[QUEUE_DEBUG] Checking queue for tasks (acquiring lock)...")
            with queue_lock:
                if task_queue:
                    task_to_run = task_queue.popleft()
                    current_queue_size = len(task_queue)
                    log_message(f"[QUEUE_DEBUG] Task popped from queue. Remaining: {current_queue_size}")
                else:
                    log_message("[QUEUE_DEBUG] Queue is empty. Breaking loop.")
                    break
            log_message("[QUEUE_DEBUG] Queue lock released.")

            if not task_to_run:
                 log_message("[QUEUE_DEBUG] Warning: No task found after lock release, but loop didn't break?")
                 continue

            # æ›´æ–°çŠ¶æ€ï¼šæ˜¾ç¤ºæ­£åœ¨å¤„ç†å’Œé˜Ÿåˆ—å¤§å°
            with results_lock:
                current_images_copy = accumulated_image_results[:]
                current_video = last_video_result
            log_message(f"[QUEUE_DEBUG] Preparing to yield 'Processing' status. Queue: {current_queue_size}")
            yield {
                queue_status_display: gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: æ˜¯"),
                output_gallery: gr.update(value=current_images_copy),
                output_video: gr.update(value=current_video)
            }
            log_message(f"[QUEUE_DEBUG] Yielded 'Processing' status.")

            if task_to_run:
                log_message(f"[QUEUE_DEBUG] Starting execution for popped task. Remaining queue: {current_queue_size}")
                
                # --- KSampler Check and Tab Switch ---
                # task_to_run is the tuple: (inputimage1, input_video, dynamic_positive_prompts_values, 
                #                           prompt_text_negative, json_file, hua_width, hua_height, 
                #                           dynamic_loras_values, ...)
                # json_file is at index 4 of task_to_run (0-indexed)
                current_task_json_file = task_to_run[4] 
                should_switch_to_preview = False
                if current_task_json_file and isinstance(current_task_json_file, str): # Ensure it's a string before using
                    json_path_for_check = os.path.join(OUTPUT_DIR, current_task_json_file)
                    if os.path.exists(json_path_for_check):
                        try:
                            with open(json_path_for_check, "r", encoding="utf-8") as f_check:
                                workflow_prompt = json.load(f_check)
                            VALID_KSAMPLER_CLASS_TYPES = ["KSampler", "KSamplerAdvanced", "KSamplerSelect"]
                            for node_id, node_data in workflow_prompt.items():
                                class_type = node_data.get("class_type")
                                if isinstance(node_data, dict) and class_type in VALID_KSAMPLER_CLASS_TYPES:
                                    should_switch_to_preview = True
                                    log_message(f"[QUEUE_DEBUG] KSampler-like node (type: {class_type}) found in {current_task_json_file}. Will switch to preview tab.")
                                    break
                        except Exception as e_json_check:
                            log_message(f"[QUEUE_DEBUG] Error checking for KSampler in {current_task_json_file}: {e_json_check}")
                
                if should_switch_to_preview:
                    yield { main_output_tabs_component: gr.Tabs(selected="tab_k_sampler_preview") }
                # --- End KSampler Check ---

                progress(0, desc=f"å¤„ç†ä»»åŠ¡ (é˜Ÿåˆ—å‰©ä½™ {current_queue_size})")
                log_message(f"[QUEUE_DEBUG] Progress set to 0. Desc: Processing task (Queue remaining {current_queue_size})")
                
                # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
                future = executor.submit(process_task, task_to_run)
                log_message(f"[QUEUE_DEBUG] Task submitted to thread pool")

                task_interrupted_by_user = False
                # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œä½†æ¯0.1ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œå¹¶æ£€æŸ¥ä¸­æ–­ä¿¡å·
                while not future.done():
                    if interrupt_requested_event.is_set():
                        log_message("[QUEUE_DEBUG] User interrupt detected while waiting for future.")
                        task_interrupted_by_user = True
                        break
                    time.sleep(0.1)
                    # åœ¨ç­‰å¾…æœŸé—´ï¼Œä¹Ÿéœ€è¦ä» results_lock ä¸­è·å–æœ€æ–°çš„ç´¯ç§¯ç»“æœ
                    with results_lock:
                        current_images_while_waiting = accumulated_image_results[:]
                        current_video_while_waiting = last_video_result
                    yield {
                        queue_status_display: gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: æ˜¯ (è¿è¡Œä¸­)"),
                        output_gallery: gr.update(value=current_images_while_waiting),
                        output_video: gr.update(value=current_video_while_waiting)
                    }
                
                if task_interrupted_by_user:
                    log_message("[QUEUE_DEBUG] Task was interrupted by user. Setting result to USER_INTERRUPTED.")
                    output_type, new_paths = "USER_INTERRUPTED", None
                    interrupt_requested_event.clear() # æ¸…é™¤æ ‡å¿—

                    # --- æ–°å¢ï¼šå°è¯•é‡ç½® executor ---
                    # global executor # å·²åœ¨å‡½æ•°é¡¶éƒ¨å£°æ˜
                    log_message("[QUEUE_DEBUG] Attempting to shutdown and recreate executor due to user interrupt.")
                    executor.shutdown(wait=False) 
                    executor = ThreadPoolExecutor(max_workers=1)
                    log_message("[QUEUE_DEBUG] Executor shutdown and recreated.")
                    # --- æ–°å¢ç»“æŸ ---
                else:
                    try:
                        output_type, new_paths = future.result()
                        log_message(f"[QUEUE_DEBUG] Future completed. Type: {output_type}, Paths: {'Yes' if new_paths else 'No'}")
                    except Exception as e:
                        log_message(f"[QUEUE_DEBUG] Exception when getting future result: {e}")
                        output_type, new_paths = None, None # ä»»åŠ¡æ‰§è¡Œå‡ºé”™
                
                progress(1) # ä»»åŠ¡å®Œæˆï¼ˆæ— è®ºæˆåŠŸä¸å¦ï¼Œæˆ–è¢«ä¸­æ–­ï¼‰
                log_message(f"[QUEUE_DEBUG] Progress set to 1.")

                if output_type == "USER_INTERRUPTED":
                    log_message("[QUEUE_DEBUG] Task was interrupted by user. Updating UI.")
                    # current_queue_size å·²ç»æ˜¯æœ€æ–°çš„ï¼ˆåœ¨ task_to_run = task_queue.popleft() ä¹‹åï¼‰
                    with results_lock:
                        current_images_copy = accumulated_image_results[:]
                        current_video = last_video_result
                    yield {
                        queue_status_display: gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: å¦ (å·²ä¸­æ–­)"),
                        output_gallery: gr.update(value=current_images_copy),
                        output_video: gr.update(value=current_video),
                    }
                    log_message(f"[QUEUE_DEBUG] Yielded USER_INTERRUPTED update. Queue: {current_queue_size}")
                    # è®©å¾ªç¯ç»§ç»­ï¼Œä»¥ä¾¿ finally å—å¯ä»¥æ­£ç¡®æ¸…ç† processing_event
                    # å¦‚æœè¿™æ˜¯æœ€åä¸€ä¸ªä»»åŠ¡ï¼Œå¾ªç¯ä¼šåœ¨ä¸‹ä¸€æ¬¡è¿­ä»£æ—¶è‡ªç„¶ç»“æŸ

                elif output_type == "COMFYUI_REJECTED":
                    log_message("[QUEUE_DEBUG] Task rejected by ComfyUI backend or critical error in start_queue. Clearing remaining Gradio queue.")
                    with queue_lock:
                        task_queue.clear() # æ¸…ç©ºGradioé˜Ÿåˆ—ä¸­æ‰€æœ‰å‰©ä½™ä»»åŠ¡
                        current_queue_size = len(task_queue) # åº”ä¸º0
                    with results_lock:
                        current_images_copy = accumulated_image_results[:]
                        current_video = last_video_result
                    log_message(f"[QUEUE_DEBUG] Preparing to yield COMFYUI_REJECTED update. Queue: {current_queue_size}")
                    yield {
                         queue_status_display: gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: æ˜¯ (åç«¯é”™è¯¯ï¼Œé˜Ÿåˆ—å·²æ¸…ç©º)"),
                         output_gallery: gr.update(value=current_images_copy),
                         output_video: gr.update(value=current_video),
                    }
                    log_message(f"[QUEUE_DEBUG] Yielded COMFYUI_REJECTED update. Loop will now check empty queue and exit to finally.")
                
                elif new_paths: # ä»»åŠ¡æˆåŠŸä¸”æœ‰ç»“æœ (output_type ä¸æ˜¯ COMFYUI_REJECTED or USER_INTERRUPTED)
                    log_message(f"[QUEUE_DEBUG] Task successful, got {len(new_paths)} new paths of type '{output_type}'.")
                    update_dict = {}
                    with results_lock:
                        if output_type == 'image':
                            if queue_count == 1: # å•ä»»åŠ¡æ¨¡å¼
                                accumulated_image_results = new_paths # æ›¿æ¢
                            else: # æ‰¹é‡ä»»åŠ¡æ¨¡å¼
                                current_batch_image_results.extend(new_paths) # ç´¯åŠ åˆ°å½“å‰æ‰¹æ¬¡
                                accumulated_image_results = current_batch_image_results[:] # æ›´æ–°å…¨å±€ç´¯ç§¯ç»“æœ
                            last_video_result = None # æ¸…é™¤æ—§è§†é¢‘ï¼ˆå¦‚æœæ˜¯å›¾ç‰‡ä»»åŠ¡ï¼‰
                            update_dict[output_gallery] = gr.update(value=accumulated_image_results[:], visible=True)
                            update_dict[output_video] = gr.update(value=None, visible=False) # éšè—è§†é¢‘è¾“å‡º
                        elif output_type == 'video':
                            last_video_result = new_paths[0] if new_paths else None # è§†é¢‘åªæ˜¾ç¤ºæœ€æ–°çš„ä¸€ä¸ª
                            accumulated_image_results = [] # æ¸…é™¤æ—§å›¾ç‰‡ï¼ˆå¦‚æœæ˜¯è§†é¢‘ä»»åŠ¡ï¼‰
                            update_dict[output_gallery] = gr.update(value=[], visible=False) # éšè—å›¾ç‰‡è¾“å‡º
                            update_dict[output_video] = gr.update(value=last_video_result, visible=True) # æ˜¾ç¤ºè§†é¢‘è¾“å‡º
                        else: # æœªçŸ¥ç±»å‹ (ç†è®ºä¸Šä¸åº”å‘ç”Ÿï¼Œå› ä¸º generate_image æ§åˆ¶äº† output_type)
                             log_message(f"[QUEUE_DEBUG] Unknown or unexpected output type '{output_type}'. Treating as image.")
                             # é»˜è®¤ä¸ºå›¾ç‰‡å¤„ç†æˆ–ä¿æŒåŸæ ·
                             accumulated_image_results.extend(new_paths) # å°è¯•æ·»åŠ 
                             update_dict[output_gallery] = gr.update(value=accumulated_image_results[:])
                             update_dict[output_video] = gr.update(value=last_video_result)

                        log_message(f"[QUEUE_DEBUG] Updated results (lock acquired). Images: {len(accumulated_image_results)}, Video: {last_video_result is not None}")

                    update_dict[queue_status_display] = gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: æ˜¯ (å®Œæˆ)")
                    log_message(f"[QUEUE_DEBUG] Preparing to yield success update. Queue: {current_queue_size}")
                    yield update_dict
                    log_message(f"[QUEUE_DEBUG] Yielded success update.")
                else: # ä»»åŠ¡å¤±è´¥ (output_type is None, or new_paths is None/empty but not COMFYUI_REJECTED)
                    log_message("[QUEUE_DEBUG] Task failed or returned no paths (general failure, not COMFYUI_REJECTED).")
                    with results_lock:
                        current_images_copy = accumulated_image_results[:]
                        current_video = last_video_result
                    log_message(f"[QUEUE_DEBUG] Preparing to yield general failure update. Queue: {current_queue_size}")
                    yield {
                         queue_status_display: gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: æ˜¯ (å¤±è´¥)"),
                         output_gallery: gr.update(value=current_images_copy),
                         output_video: gr.update(value=current_video),
                    }
                    log_message(f"[QUEUE_DEBUG] Yielded general failure update.")

    finally:
        log_message(f"[QUEUE_DEBUG] Entering finally block. Clearing processing_event (was {processing_event.is_set()}).")
        processing_event.clear()
        log_message(f"[QUEUE_DEBUG] processing_event cleared (is now {processing_event.is_set()}).")
        with queue_lock: current_queue_size = len(task_queue)
        with results_lock:
            final_images = accumulated_image_results[:]
            final_video = last_video_result
        log_message(f"[QUEUE_DEBUG] Preparing to yield final status update. Queue: {current_queue_size}, Processing: No. Switching to results tab.")
        yield {
            queue_status_display: gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: å¦"),
            output_gallery: gr.update(value=final_images),
            output_video: gr.update(value=final_video),
            main_output_tabs_component: gr.Tabs(selected="tab_generate_result") # Switch back to results tab
        }
        log_message("[QUEUE_DEBUG] Yielded final status update. Exiting run_queued_tasks.")

# --- èµåŠ©ç å¤„ç†å‡½æ•° ---
def show_sponsor_code():
    sponsor_info = get_sponsor_html()
    # è¿”å›ä¸€ä¸ªæ›´æ–°æŒ‡ä»¤ï¼Œè®© Markdown ç»„ä»¶å¯è§å¹¶æ˜¾ç¤ºå†…å®¹
    return gr.update(value=sponsor_info, visible=True)

# --- æ¸…é™¤å‡½æ•° ---
def clear_queue():
    global task_queue, queue_lock, interrupt_requested_event, processing_event
    
    action_log_messages = [] # ç”¨äº gr.Info()

    with queue_lock:
        is_currently_processing_a_task_in_comfyui = processing_event.is_set()
        num_tasks_waiting_in_gradio_queue = len(task_queue)

        log_message(f"[CLEAR_QUEUE] Entry. Gradio pending queue size: {num_tasks_waiting_in_gradio_queue}, ComfyUI processing active: {is_currently_processing_a_task_in_comfyui}")

        if is_currently_processing_a_task_in_comfyui and num_tasks_waiting_in_gradio_queue == 0:
            # æƒ…å†µ1: ComfyUI æ­£åœ¨å¤„ç†ä¸€ä¸ªä»»åŠ¡ (è¯¥ä»»åŠ¡å·²ä»Gradioé˜Ÿåˆ—å–å‡ºï¼Œåœ¨executorä¸­è¿è¡Œ), 
            # ä¸” Gradio çš„ç­‰å¾…é˜Ÿåˆ—ä¸ºç©ºã€‚è¿™æ˜¯â€œä»…å‰©å½“å‰ä»»åŠ¡â€çš„æƒ…å†µï¼Œéœ€è¦ä¸­æ–­å®ƒã€‚
            log_message("[CLEAR_QUEUE] Action: Interrupting the single, currently running ComfyUI task.")
            
            # å‘é€ HTTP ä¸­æ–­è¯·æ±‚åˆ° ComfyUI
            interrupt_comfyui_status_message = trigger_comfyui_interrupt() 
            action_log_messages.append(f"å°è¯•ä¸­æ–­ ComfyUI å½“å‰ä»»åŠ¡: {interrupt_comfyui_status_message}")
            log_message(f"[CLEAR_QUEUE] ComfyUI interrupt triggered via HTTP: {interrupt_comfyui_status_message}")

            # è®¾ç½® Gradio å†…éƒ¨çš„ä¸­æ–­æ ‡å¿—ã€‚
            # run_queued_tasks ä¸­çš„å¾ªç¯ä¼šæ£€æµ‹åˆ°è¿™ä¸ªäº‹ä»¶ï¼Œå¹¶ä¸ºæ­£åœ¨è¿è¡Œçš„ future å¯¹è±¡è¿›è¡Œç›¸åº”å¤„ç†ã€‚
            interrupt_requested_event.set()
            log_message("[CLEAR_QUEUE] Gradio internal interrupt_requested_event was SET.")
            
            # task_queue æ­¤æ—¶åº”ä¸ºç©ºï¼Œæ— éœ€ clearã€‚
            
        elif num_tasks_waiting_in_gradio_queue > 0:
            # æƒ…å†µ2: Gradio çš„ç­‰å¾…é˜Ÿåˆ—ä¸­æœ‰ä»»åŠ¡ã€‚æ¸…é™¤è¿™äº›ç­‰å¾…ä¸­çš„ä»»åŠ¡ã€‚
            # ä¸ä¸­æ–­å¯èƒ½æ­£åœ¨ ComfyUI ä¸­è¿è¡Œçš„ä»»åŠ¡ã€‚
            cleared_count = num_tasks_waiting_in_gradio_queue
            task_queue.clear() # æ¸…ç©º Gradio çš„ç­‰å¾…é˜Ÿåˆ—
            log_message(f"[CLEAR_QUEUE] Action: Cleared {cleared_count} task(s) from Gradio's queue. Any ComfyUI task currently processing was NOT interrupted by this action.")
            action_log_messages.append(f"å·²æ¸…é™¤ Gradio é˜Ÿåˆ—ä¸­çš„ {cleared_count} ä¸ªç­‰å¾…ä»»åŠ¡ã€‚")
            
            # å¦‚æœä¹‹å‰æœ‰ä¸€ä¸ªå¤–éƒ¨ä¸­æ–­è¯·æ±‚çš„æ ‡å¿— (ä¾‹å¦‚ï¼Œé€šè¿‡å·²è¢«ç§»é™¤çš„ç‹¬ç«‹ä¸­æ–­æŒ‰é’®è®¾ç½®çš„ï¼Œç†è®ºä¸Šä¸å¤ªå¯èƒ½å‘ç”Ÿ)
            # å¹¶ä¸”æˆ‘ä»¬è¿™æ¬¡ *æ²¡æœ‰* å°è¯•ä¸­æ–­ ComfyUIï¼Œé‚£ä¹ˆæ¸…é™¤é‚£ä¸ªæ—§çš„æ ‡å¿—æ˜¯å®‰å…¨çš„ã€‚
            if interrupt_requested_event.is_set():
                interrupt_requested_event.clear()
                log_message("[CLEAR_QUEUE] Cleared a pre-existing interrupt_requested_event because we are only clearing the Gradio queue this time.")
        else:
            # æƒ…å†µ3: ComfyUI æ²¡æœ‰åœ¨å¤„ç†ä»»åŠ¡ï¼ŒGradio çš„ç­‰å¾…é˜Ÿåˆ—ä¹Ÿä¸ºç©ºã€‚æ²¡ä»€ä¹ˆå¯åšçš„ã€‚
            log_message("[CLEAR_QUEUE] Action: No tasks currently processing in ComfyUI and Gradio queue is empty. Nothing to clear or interrupt.")
            action_log_messages.append("é˜Ÿåˆ—å·²ä¸ºç©ºï¼Œæ— ä»»åŠ¡å¤„ç†ä¸­ã€‚")

    # é€šè¿‡ gr.Info() æ˜¾ç¤ºæ“ä½œæ‘˜è¦ç»™ç”¨æˆ·
    if action_log_messages:
        gr.Info(" ".join(action_log_messages))

    # æ›´æ–°é˜Ÿåˆ—çŠ¶æ€çš„UIæ˜¾ç¤º
    with queue_lock: # é‡æ–°è·å–é”ä»¥è·å¾—æœ€æ–°çš„é˜Ÿåˆ—å¤§å° (å¦‚æœæ¸…é™¤äº†ï¼Œåº”è¯¥æ˜¯0)
        current_gradio_queue_size_for_display = len(task_queue) 
    
    # processing_event çš„çŠ¶æ€ç”± run_queued_tasks çš„ä¸»å¾ªç¯å’Œ finally å—ç®¡ç†ã€‚
    # å¦‚æœæˆ‘ä»¬é€šè¿‡æ­¤å‡½æ•°ä¸­æ–­äº†ä¸€ä¸ªä»»åŠ¡ï¼Œrun_queued_tasks çš„ finally å—æœ€ç»ˆä¼šæ¸…é™¤ processing_eventã€‚
    # å¦‚æœæˆ‘ä»¬åªæ¸…é™¤äº†ç­‰å¾…é˜Ÿåˆ—ï¼Œprocessing_event å¯¹äºæ­£åœ¨è¿è¡Œä»»åŠ¡çš„çŠ¶æ€ä¼šä¿æŒï¼Œç›´åˆ°å®ƒè‡ªç„¶å®Œæˆæˆ–è¢«å…¶ä»–æ–¹å¼ä¸­æ–­ã€‚
    current_processing_status_for_display = processing_event.is_set()
    
    log_message(f"[CLEAR_QUEUE] Exit. Gradio queue size for display: {current_gradio_queue_size_for_display}, ComfyUI processing status for display: {current_processing_status_for_display}")
    
    return gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_gradio_queue_size_for_display} | å¤„ç†ä¸­: {'æ˜¯' if current_processing_status_for_display else 'å¦'}")

def clear_history():
    global accumulated_image_results, last_video_result
    with results_lock:
        accumulated_image_results.clear()
        last_video_result = None
    log_message("å›¾åƒå’Œè§†é¢‘å†å²å·²æ¸…é™¤ã€‚")
    with queue_lock: current_queue_size = len(task_queue)
    return {
        output_gallery: gr.update(value=[]), # æ¸…ç©ºä½†ä¸éšè—
        output_video: gr.update(value=None), # æ¸…ç©ºä½†ä¸éšè—
        queue_status_display: gr.update(value=f"é˜Ÿåˆ—ä¸­: {current_queue_size} | å¤„ç†ä¸­: {'æ˜¯' if processing_event.is_set() else 'å¦'}")
    }


# --- Gradio ç•Œé¢ ---

# Combine imported HACKER_CSS with monitor CSS
combined_css = HACKER_CSS + "\n" + monitor_css

# æ£€æŸ¥ Gradio ç‰ˆæœ¬ä»¥æ”¯æŒå‘ä¸‹å…¼å®¹
GRADIO_VERSION = gr.__version__
GRADIO_SUPPORTS_NEW_API = version.parse(GRADIO_VERSION) >= version.parse("4.0.0")

with gr.Blocks() as demo:
    with gr.Tab("å°è£…comfyuiå·¥ä½œæµ"):
        with gr.Row():
           with gr.Column():  # å·¦ä¾§åˆ—
               # --- æ·»åŠ å®æ—¶æ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ (åŒ…å«ç³»ç»Ÿç›‘æ§) ---
               with gr.Accordion("å®æ—¶æ—¥å¿— (ComfyUI)", open=True, elem_classes="log-display-container"): # ä¿æŒæ—¥å¿—åŒºåŸŸæ‰“å¼€
                   with gr.Group(elem_id="log_area_relative_wrapper"): # æ–°å¢å†…éƒ¨ Group ç”¨äºå®šä½ç³»ç»Ÿç›‘æ§
                       log_display = gr.Textbox(
                           label="æ—¥å¿—è¾“å‡º",
                           lines=20,
                           max_lines=20,
                           autoscroll=True,
                           interactive=False,
                           elem_classes="log-display-container"
                       )
                       # ç³»ç»Ÿç›‘æ§ HTML è¾“å‡ºç»„ä»¶
                       floating_monitor_html_output = gr.HTML(elem_classes="floating-monitor-outer-wrapper")
                
               image_accordion = gr.Accordion("ä¸Šä¼ å›¾åƒ (æŠ˜å ,æœ‰gradioä¼ å…¥å›¾åƒèŠ‚ç‚¹æ‰ä¼šæ˜¾ç¤ºä¸Šä¼ )", visible=True, open=True)
               with image_accordion:
                   input_image = gr.Image(type="pil", label="ä¸Šä¼ å›¾åƒ", height=256, width=256)
    
               # --- æ·»åŠ è§†é¢‘ä¸Šä¼ ç»„ä»¶ ---
               video_accordion = gr.Accordion("ä¸Šä¼ è§†é¢‘ (æŠ˜å ,æœ‰gradioä¼ å…¥è§†é¢‘èŠ‚ç‚¹æ‰ä¼šæ˜¾ç¤ºä¸Šä¼ )", visible=False, open=True) # åˆå§‹éšè—
               with video_accordion:
                   # ä½¿ç”¨ filepath ç±»å‹ï¼Œå› ä¸º ComfyUI èŠ‚ç‚¹éœ€è¦æ–‡ä»¶å
                   # sources=["upload"] é™åˆ¶ä¸ºä»…ä¸Šä¼ 
                   input_video = gr.Video(label="ä¸Šä¼ è§†é¢‘", sources=["upload"], height=256, width=256)
    
               with gr.Row():
                   with gr.Column(scale=3):
                       json_dropdown = gr.Dropdown(choices=get_json_files(), label="é€‰æ‹©å·¥ä½œæµ")
                   with gr.Column(scale=1):
                       with gr.Column(scale=1): # è°ƒæ•´æ¯”ä¾‹ä½¿æŒ‰é’®ä¸è‡³äºå¤ªå®½
                           refresh_button = gr.Button("ğŸ”„ åˆ·æ–°å·¥ä½œæµ")
                       with gr.Column(scale=1):
                           refresh_model_button = gr.Button("ğŸ”„ åˆ·æ–°æ¨¡å‹")
    
    
    
               with gr.Row():
                   with gr.Accordion("æ­£å‘æç¤ºæ–‡æœ¬(æŠ˜å )", open=True) as positive_prompt_col:
                       # prompt_positive = gr.Textbox(label="æ­£å‘æç¤ºæ–‡æœ¬ 1", elem_id="prompt_positive_1") # å°†è¢«åŠ¨æ€ç»„ä»¶å–ä»£
                       # prompt_positive_2 = gr.Textbox(label="æ­£å‘æç¤ºæ–‡æœ¬ 2", elem_id="prompt_positive_2")
                       # prompt_positive_3 = gr.Textbox(label="æ­£å‘æç¤ºæ–‡æœ¬ 3", elem_id="prompt_positive_3")
                       # prompt_positive_4 = gr.Textbox(label="æ­£å‘æç¤ºæ–‡æœ¬ 4", elem_id="prompt_positive_4")
                       # --- åŠ¨æ€æ­£å‘æç¤ºè¯ç»„ä»¶ ---
                       positive_prompt_texts = []
                       for i in range(MAX_DYNAMIC_COMPONENTS):
                           positive_prompt_texts.append(
                               gr.Textbox(label=f"æ­£å‘æç¤º {i+1}", visible=False, elem_id=f"dynamic_positive_prompt_{i+1}")
                           )
                       # --- åŠ¨æ€æ­£å‘æç¤ºè¯ç»„ä»¶ç»“æŸ ---
               with gr.Column() as negative_prompt_col: # è´Ÿå‘æç¤ºä¿æŒå•ä¸ª
                   prompt_negative = gr.Textbox(label="è´Ÿå‘æç¤ºæ–‡æœ¬", elem_id="prompt_negative")
    
               with gr.Row() as resolution_row:
                   with gr.Column(scale=1):
                       resolution_dropdown = gr.Dropdown(choices=resolution_presets, label="åˆ†è¾¨ç‡é¢„è®¾", value=resolution_presets[0])
                   with gr.Column(scale=1):
                       with gr.Accordion("å®½åº¦å’Œé«˜åº¦è®¾ç½®", open=False):
                           with gr.Column(scale=1):
                               hua_width = gr.Number(label="å®½åº¦", value=512, minimum=64, step=64, elem_id="hua_width_input")
                               hua_height = gr.Number(label="é«˜åº¦", value=512, minimum=64, step=64, elem_id="hua_height_input")
                               ratio_display = gr.Markdown("å½“å‰æ¯”ä¾‹: 1:1")
                       with gr.Row():
                           with gr.Column(scale=1):
                              flip_btn = gr.Button("â†” åˆ‡æ¢å®½é«˜")
    
    
    

    
    
    
    
    
    
    
           with gr.Column(): # å³ä¾§åˆ—
               with gr.Tabs(elem_id="main_output_tabs") as main_output_tabs_component: # WRAPPER TABS
                   with gr.Tab("ç”Ÿæˆç»“æœ", id="tab_generate_result"):
                       output_gallery = gr.Gallery(label="ç”Ÿæˆå›¾ç‰‡ç»“æœ", columns=3, height=600, preview=True, object_fit="contain", visible=False) # ä¿æŒåŸæ ·
                       output_video = gr.Video(label="ç”Ÿæˆè§†é¢‘ç»“æœ", height=600, autoplay=True, loop=True, visible=False) # ä¿æŒåŸæ ·
                   with gr.Tab("ké‡‡æ ·é¢„è§ˆ", id="tab_k_sampler_preview"):
                       with gr.Tab("å®æ—¶é¢„è§ˆ"): # This is a nested Tab, not an issue for the parent switching
                           live_preview_image = gr.Image(label="å®æ—¶é¢„è§ˆ", type="pil", interactive=False, height=512, show_label=False)
                       with gr.Tab("çŠ¶æ€"): # This is a nested Tab
                           live_preview_status = gr.Textbox(label="é¢„è§ˆçŠ¶æ€", interactive=False, lines=2)
                   with gr.Tab("é¢„è§ˆæ‰€æœ‰è¾“å‡ºå›¾ç‰‡", id="tab_all_outputs_preview"):
                       output_preview_gallery = gr.Gallery(label="è¾“å‡ºå›¾ç‰‡é¢„è§ˆ", columns=4, height="auto", preview=True, object_fit="contain")
                       load_output_button = gr.Button("åŠ è½½è¾“å‡ºå›¾ç‰‡")



    
               # --- æ·»åŠ é˜Ÿåˆ—æ§åˆ¶æŒ‰é’® ---
               with gr.Row():
                   queue_status_display = gr.Markdown("é˜Ÿåˆ—ä¸­: 0 | å¤„ç†ä¸­: å¦") # ç§»åˆ°æŒ‰é’®ä¸Šæ–¹
    
               with gr.Row():
                   with gr.Row():
                       run_button = gr.Button("ğŸš€ å¼€å§‹è·‘å›¾ (åŠ å…¥é˜Ÿåˆ—)", variant="primary",elem_id="align-center")
                       clear_queue_button = gr.Button("ğŸ§¹ æ¸…é™¤é˜Ÿåˆ—",elem_id="align-center")
                       
    
                   with gr.Row():
                       clear_history_button = gr.Button("ğŸ—‘ï¸ æ¸…é™¤æ˜¾ç¤ºå†å²")
                        # --- æ·»åŠ èµåŠ©æŒ‰é’®å’Œæ˜¾ç¤ºåŒºåŸŸ ---
                       sponsor_button = gr.Button("ğŸ’– èµåŠ©ä½œè€…")
                   with gr.Row():
                       queue_count = gr.Number(label="é˜Ÿåˆ—æ•°é‡", value=1, minimum=1, step=1, precision=0)

    
    
    
    
               sponsor_display = gr.Markdown(visible=False) # åˆå§‹éšè—
               with gr.Row():

                   # interrupt_action_status Textbox å·²ç§»é™¤ï¼Œå°†é€šè¿‡ gr.Info() æ˜¾ç¤ºå¼¹çª—
                   with gr.Column(scale=1, visible=False) as seed_options_col: # ç§å­é€‰é¡¹åˆ—ï¼Œåˆå§‹éšè—
                       seed_mode_dropdown = gr.Dropdown(
                           choices=["éšæœº", "é€’å¢", "é€’å‡", "å›ºå®š"],
                           value="éšæœº",
                           label="ç§å­æ¨¡å¼",
                           elem_id="seed_mode_dropdown"
                       )
                       fixed_seed_input = gr.Number(
                           label="å›ºå®šç§å­å€¼",
                           value=0,
                           minimum=0,
                           maximum=0xffffffff, # Max unsigned 32-bit int
                           step=1,
                           precision=0,
                           visible=False, # åˆå§‹éšè—ï¼Œä»…åœ¨æ¨¡å¼ä¸º "å›ºå®š" æ—¶æ˜¾ç¤º
                           elem_id="fixed_seed_input"
                       )
                       
                   with gr.Column(scale=1):
                       hua_unet_dropdown = gr.Dropdown(choices=unet_list, label="é€‰æ‹© UNet æ¨¡å‹", value="None", elem_id="hua_unet_dropdown", visible=False) # åˆå§‹éšè—


               with gr.Row():
                   with gr.Column(scale=1):
                       # hua_lora_dropdown = gr.Dropdown(choices=lora_list, label="é€‰æ‹© Lora æ¨¡å‹ 1", value="None", elem_id="hua_lora_dropdown", visible=False) # åˆå§‹éšè—
                       # hua_lora_dropdown_2 = gr.Dropdown(choices=lora_list, label="é€‰æ‹© Lora æ¨¡å‹ 2", value="None", elem_id="hua_lora_dropdown_2", visible=False) # æ–°å¢ï¼Œåˆå§‹éšè—
                       # hua_lora_dropdown_3 = gr.Dropdown(choices=lora_list, label="é€‰æ‹© Lora æ¨¡å‹ 3", value="None", elem_id="hua_lora_dropdown_3", visible=False) # æ–°å¢ï¼Œåˆå§‹éšè—
                       # hua_lora_dropdown_4 = gr.Dropdown(choices=lora_list, label="é€‰æ‹© Lora æ¨¡å‹ 4", value="None", elem_id="hua_lora_dropdown_4", visible=False) # æ–°å¢ï¼Œåˆå§‹éšè—
                       # --- åŠ¨æ€ Lora ä¸‹æ‹‰æ¡† ---
                       lora_dropdowns = []
                       for i in range(MAX_DYNAMIC_COMPONENTS):
                           lora_dropdowns.append(
                               gr.Dropdown(choices=lora_list, label=f"Lora {i+1}", value="None", visible=False, elem_id=f"dynamic_lora_dropdown_{i+1}")
                           )
                       # --- åŠ¨æ€ Lora ä¸‹æ‹‰æ¡†ç»“æŸ ---
                   with gr.Column(scale=1): # Checkpoint å’Œ Unet ä¿æŒå•ä¾‹
                       hua_checkpoint_dropdown = gr.Dropdown(choices=checkpoint_list, label="é€‰æ‹© Checkpoint æ¨¡å‹", value="None", elem_id="hua_checkpoint_dropdown", visible=False) # åˆå§‹éšè—


               # --- æ·»åŠ  Float å’Œ Int è¾“å…¥ç»„ä»¶ (åˆå§‹éšè—) ---
               with gr.Row() as float_int_row: # ä¿æŒæ­¤è¡Œç”¨äºæ•´ä½“å¯è§æ€§æ§åˆ¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    with gr.Column(scale=1):
                        # hua_float_input = gr.Number(label="æµ®ç‚¹æ•°è¾“å…¥ (Float)", visible=False, elem_id="hua_float_input")
                        # hua_float_input_2 = gr.Number(label="æµ®ç‚¹æ•°è¾“å…¥ 2 (Float)", visible=False, elem_id="hua_float_input_2")
                        # hua_float_input_3 = gr.Number(label="æµ®ç‚¹æ•°è¾“å…¥ 3 (Float)", visible=False, elem_id="hua_float_input_3")
                        # hua_float_input_4 = gr.Number(label="æµ®ç‚¹æ•°è¾“å…¥ 4 (Float)", visible=False, elem_id="hua_float_input_4")
                        # --- åŠ¨æ€ Float è¾“å…¥ ---
                        float_inputs = []
                        for i in range(MAX_DYNAMIC_COMPONENTS):
                            float_inputs.append(
                                gr.Number(label=f"æµ®ç‚¹æ•° {i+1}", visible=False, elem_id=f"dynamic_float_input_{i+1}")
                            )
                    # --- åŠ¨æ€ Float è¾“å…¥ç»“æŸ ---
                    with gr.Column(scale=1):
                        # hua_int_input = gr.Number(label="æ•´æ•°è¾“å…¥ (Int)", precision=0, visible=False, elem_id="hua_int_input") # precision=0 for integer
                        # hua_int_input_2 = gr.Number(label="æ•´æ•°è¾“å…¥ 2 (Int)", precision=0, visible=False, elem_id="hua_int_input_2")
                        # hua_int_input_3 = gr.Number(label="æ•´æ•°è¾“å…¥ 3 (Int)", precision=0, visible=False, elem_id="hua_int_input_3")
                        # hua_int_input_4 = gr.Number(label="æ•´æ•°è¾“å…¥ 4 (Int)", precision=0, visible=False, elem_id="hua_int_input_4")
                        # --- åŠ¨æ€ Int è¾“å…¥ ---
                        int_inputs = []
                        for i in range(MAX_DYNAMIC_COMPONENTS):
                            int_inputs.append(
                                gr.Number(label=f"æ•´æ•° {i+1}", precision=0, visible=False, elem_id=f"dynamic_int_input_{i+1}")
                            )
                        # --- åŠ¨æ€ Int è¾“å…¥ç»“æŸ ---


               with gr.Row():
                   # interrupt_button_main_tab å·²è¢«ç§»é™¤
                   gr.Markdown('æˆ‘è¦æ‰“åä¸ª') # ä¿ç•™è¿™å¥éªšè¯                       
                   
               # with gr.Row(): # queue_status_display å·²ç§»åˆ°ä¸Šæ–¹
               #     with gr.Column(scale=1):
               #         queue_status_display = gr.Markdown("é˜Ÿåˆ—ä¸­: 0 | å¤„ç†ä¸­: å¦")
               
               

    with gr.Tab("è®¾ç½®"):
        with gr.Column(): # ä½¿ç”¨ Column å¸ƒå±€

            gr.Markdown("## ğŸ›ï¸ ComfyUI èŠ‚ç‚¹å¾½ç« æ§åˆ¶")
            gr.Markdown("æ§åˆ¶ ComfyUI ç•Œé¢ä¸­èŠ‚ç‚¹ ID å¾½ç« çš„æ˜¾ç¤ºæ–¹å¼ã€‚è®¾ç½®å®Œæˆè¯·åˆ·æ–°comfyuiç•Œé¢å³å¯ã€‚")
            node_badge_mode_radio = gr.Radio(
                choices=["Show all", "Hover", "None"],
                value="Show all", # é»˜è®¤å€¼å¯ä»¥å°è¯•ä» ComfyUI è·å–ï¼Œä½†è¿™é‡Œå…ˆè®¾ä¸º Show all
                label="é€‰æ‹©èŠ‚ç‚¹ ID å¾½ç« æ˜¾ç¤ºæ¨¡å¼"
            )
            node_badge_output_text = gr.Textbox(label="æ›´æ–°ç»“æœ", interactive=False)

            # å°†äº‹ä»¶å¤„ç†ç§»åˆ° UI å®šä¹‰ä¹‹å
            node_badge_mode_radio.change(
                fn=update_node_badge_mode,
                inputs=node_badge_mode_radio,
                outputs=node_badge_output_text
            )
            # TODO: æ·»åŠ ä¸€ä¸ªæŒ‰é’®æˆ–åœ¨åŠ è½½æ—¶å°è¯•è·å–å½“å‰è®¾ç½®å¹¶æ›´æ–° Radio çš„ value

            gr.Markdown("---") # æ·»åŠ åˆ†éš”çº¿
            gr.Markdown("## âš¡ ComfyUI æ§åˆ¶")
            gr.Markdown("é‡å¯ ComfyUI æˆ–ä¸­æ–­å½“å‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ã€‚")

            with gr.Row():
                reboot_button = gr.Button("ğŸ”„ é‡å¯ComfyUI")
                # interrupt_button (åŸä½ç½®) å·²è¢«ç§»é™¤

            reboot_output = gr.Textbox(label="é‡å¯ç»“æœ", interactive=False)
            # interrupt_output (åŸä½ç½®) å·²è¢«ç§»é™¤

            # å°†äº‹ä»¶å¤„ç†ç§»åˆ° UI å®šä¹‰ä¹‹å
            reboot_button.click(fn=reboot_manager, inputs=[], outputs=[reboot_output])
            # interrupt_button.click (åŸä½ç½®) å·²è¢«ç§»é™¤



            gr.Markdown("## âš™ï¸ æ’ä»¶æ ¸å¿ƒè®¾ç½®") 
            gr.Markdown("---")

            gr.Markdown("### ğŸ¨ åŠ¨æ€ç»„ä»¶æ•°é‡")
            gr.Markdown(
                "è®¾ç½®åœ¨UIä¸­ä¸ºæ­£å‘æç¤ºã€Loraã€æµ®ç‚¹æ•°å’Œæ•´æ•°è¾“å…¥åŠ¨æ€ç”Ÿæˆçš„ç»„ä»¶çš„æœ€å¤§æ•°é‡ã€‚\n"
                "**æ³¨æ„ï¼šæ­¤æ›´æ”¹å°†åœ¨ä¸‹æ¬¡å¯åŠ¨æ’ä»¶ (æˆ–é‡å¯ ComfyUI) åç”Ÿæ•ˆï¼Œä»¥æ”¹å˜å®é™…æ˜¾ç¤ºçš„ç»„ä»¶æ•°é‡ã€‚**"
            )
            
            # UIç»„ä»¶çš„åˆå§‹å€¼ä¹Ÿä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œç¡®ä¿æ˜¾ç¤ºçš„æ˜¯å½“å‰ç”Ÿæ•ˆçš„æˆ–å³å°†ç”Ÿæ•ˆçš„é…ç½®
            initial_max_comp_for_ui = load_plugin_settings().get("max_dynamic_components", DEFAULT_MAX_DYNAMIC_COMPONENTS)
            
            max_dynamic_components_input = gr.Number(
                label="æœ€å¤§åŠ¨æ€ç»„ä»¶æ•°é‡ (1-20)", 
                value=initial_max_comp_for_ui, 
                minimum=1, 
                maximum=20, # è®¾å®šä¸€ä¸ªåˆç†çš„ä¸Šé™
                step=1, 
                precision=0,
                elem_id="max_dynamic_components_setting_input"
            )
            save_max_components_button = gr.Button("ä¿å­˜åŠ¨æ€ç»„ä»¶æ•°é‡è®¾ç½®")
            max_components_save_status = gr.Markdown("", elem_id="max_components_save_status_md") # ç”¨äºæ˜¾ç¤ºä¿å­˜çŠ¶æ€å’Œæç¤º

            def handle_save_max_components(new_max_value_from_input):
                try:
                    # Gradio Number input might pass a float if not careful, ensure int
                    new_max_value = int(float(new_max_value_from_input)) 
                    if not (1 <= new_max_value <= 20): # åç«¯å†æ¬¡éªŒè¯èŒƒå›´
                        return gr.update(value="<p style='color:red;'>é”™è¯¯ï¼šå€¼å¿…é¡»ä»‹äº 1 å’Œ 20 ä¹‹é—´ã€‚</p>")
                except ValueError:
                    return gr.update(value="<p style='color:red;'>é”™è¯¯ï¼šè¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•´æ•°ã€‚</p>")

                # é‡æ–°åŠ è½½å½“å‰è®¾ç½®ï¼Œä»¥é˜²å…¶ä»–è®¾ç½®é¡¹è¢«æ„å¤–è¦†ç›–ï¼ˆå¦‚æœæœªæ¥æœ‰å…¶ä»–è®¾ç½®é¡¹ï¼‰
                current_settings = load_plugin_settings() 
                current_settings["max_dynamic_components"] = new_max_value
                status_message = save_plugin_settings(current_settings)
                
                # æ›´æ–°å…¨å±€MAX_DYNAMIC_COMPONENTSï¼Œä¸»è¦ç”¨äºç¡®ä¿get_workflow_defaults_and_visibilityåœ¨åŒä¸€æ¬¡ä¼šè¯ä¸­å¦‚æœè¢«è°ƒç”¨èƒ½æ‹¿åˆ°æ–°å€¼
                # ä½†è¿™ä¸ä¼šæ”¹å˜å·²ç»å®ä¾‹åŒ–çš„Gradioç»„ä»¶æ•°é‡
                # global MAX_DYNAMIC_COMPONENTS
                # MAX_DYNAMIC_COMPONENTS = new_max_value 
                # print(f"UIä¸­æ›´æ–°äº†max_dynamic_componentsçš„é…ç½®ï¼Œæ–°å€¼ä¸º: {new_max_value}ã€‚é‡å¯åç”Ÿæ•ˆäºUIç»„ä»¶æ•°é‡ã€‚")

                return gr.update(value=f"<p style='color:green;'>{status_message} è¯·é‡å¯æ’ä»¶æˆ– ComfyUI ä»¥ä½¿æ›´æ”¹ç”Ÿæ•ˆã€‚</p>")

            save_max_components_button.click(
                fn=handle_save_max_components,
                inputs=[max_dynamic_components_input],
                outputs=[max_components_save_status]
            )
            
            gr.Markdown("---") # åˆ†éš”çº¿

    with gr.Tab("ä¿¡æ¯"):
        with gr.Column():
            gr.Markdown("### â„¹ï¸ æ’ä»¶ä¸å¼€å‘è€…ä¿¡æ¯") # æ·»åŠ æ ‡é¢˜

            # GitHub Repo Button
            github_repo_btn = gr.Button("æœ¬æ’ä»¶ GitHub ä»“åº“")
            gitthub_display = gr.Markdown(visible=False) # æ­¤é€‰é¡¹å¡ä¸­ç”¨äºæ˜¾ç¤ºé“¾æ¥çš„åŒºåŸŸ
            github_repo_btn.click(lambda: gr.update(value="https://github.com/kungful/ComfyUI_to_webui.git",visible=True), inputs=[], outputs=[gitthub_display]) # ä¿®æ­£: æŒ‡å‘ gitthub_display

            # Free Mirror Button
            free_mirror_btn = gr.Button("å¼€å‘è€…çš„å…è´¹é•œåƒ")
            free_mirror_diplay = gr.Markdown(visible=False) # æ­¤é€‰é¡¹å¡ä¸­ç”¨äºæ˜¾ç¤ºé“¾æ¥çš„åŒºåŸŸ
            free_mirror_btn.click(lambda: gr.update(value="https://www.xiangongyun.com/image/detail/7b36c1a3-da41-4676-b5b3-03ec25d6e197",visible=True), inputs=[], outputs=[free_mirror_diplay]) # ä¿®æ­£: æŒ‡å‘ free_mirror_diplay

            # Sponsor Button & Display Area
            sponsor_info_btn = gr.Button("ğŸ’– èµåŠ©å¼€å‘è€…")
            info_sponsor_display = gr.Markdown(visible=False) # æ­¤é€‰é¡¹å¡ä¸­ç”¨äºæ˜¾ç¤ºèµåŠ©ä¿¡æ¯çš„åŒºåŸŸ
            sponsor_info_btn.click(fn=show_sponsor_code, inputs=[], outputs=[info_sponsor_display]) # ç›®æ ‡æ–°çš„æ˜¾ç¤ºåŒºåŸŸ

            # Contact Button & Display Area
            contact_btn = gr.Button("å¼€å‘è€…è”ç³»æ–¹å¼")
            contact_display = gr.Markdown(visible=False) # è”ç³»ä¿¡æ¯æ˜¾ç¤ºåŒºåŸŸ
            # ä½¿ç”¨ lambda æ›´æ–° Markdown ç»„ä»¶çš„å€¼å¹¶ä½¿å…¶å¯è§
            contact_btn.click(lambda: gr.update(value="**é‚®ç®±:** blenderkrita@gmail.com", visible=True), inputs=[], outputs=[contact_display])

            # Tutorial Button
            tutorial_btn = gr.Button("ä½¿ç”¨æ•™ç¨‹ (GitHub)")
            tutorial_display = gr.Markdown(visible=False) # æ­¤é€‰é¡¹å¡ä¸­ç”¨äºæ˜¾ç¤ºé“¾æ¥çš„åŒºåŸŸ
            tutorial_btn.click(lambda: gr.update(value="https://github.com/kungful/ComfyUI_to_webui.git",visible=True), inputs=[], outputs=[tutorial_display]) # ä¿®æ­£: æŒ‡å‘ tutorial_display

            # æ·»åŠ ä¸€äº›é—´è·æˆ–è¯´æ˜
            gr.Markdown("---")
            gr.Markdown("ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®è·å–ç›¸å…³ä¿¡æ¯æˆ–è·³è½¬é“¾æ¥ã€‚")

    with gr.Tab("API JSON ç®¡ç†"):
        define_api_json_management_ui()


    # --- äº‹ä»¶å¤„ç† ---

    def refresh_workflow_and_ui(current_selected_json_file):
        log_message(f"[REFRESH_WORKFLOW_UI] Triggered. Current selection: {current_selected_json_file}")
        
        new_json_choices = get_json_files()
        log_message(f"[REFRESH_WORKFLOW_UI] New JSON choices: {new_json_choices}")

        json_to_load_for_ui_update = None
        
        if current_selected_json_file and current_selected_json_file in new_json_choices:
            json_to_load_for_ui_update = current_selected_json_file
            log_message(f"[REFRESH_WORKFLOW_UI] Current selection '{current_selected_json_file}' is still valid.")
        elif new_json_choices:
            json_to_load_for_ui_update = new_json_choices[0]
            log_message(f"[REFRESH_WORKFLOW_UI] Current selection '{current_selected_json_file}' is invalid or not present. Defaulting to first new choice: '{json_to_load_for_ui_update}'.")
        else:
            # No JSON files available at all
            log_message(f"[REFRESH_WORKFLOW_UI] No JSON files available after refresh.")
            # update_ui_on_json_change(None) will handle hiding/resetting components.

        # Get the UI updates based on the json_to_load_for_ui_update
        # update_ui_on_json_change returns a tuple of gr.update objects
        ui_updates_tuple = update_ui_on_json_change(json_to_load_for_ui_update)
        
        # The first part of the return will be the update for the json_dropdown itself
        dropdown_update = gr.update(choices=new_json_choices, value=json_to_load_for_ui_update)
        
        # Combine the dropdown update with the rest of the UI updates
        final_updates = (dropdown_update,) + ui_updates_tuple
        log_message(f"[REFRESH_WORKFLOW_UI] Returning {len(final_updates)} updates. Dropdown will be set to '{json_to_load_for_ui_update}'.")
        return final_updates

    # --- èŠ‚ç‚¹å¾½ç« è®¾ç½®äº‹ä»¶ (å·²åœ¨ Tab å†…å®šä¹‰) ---
    # node_badge_mode_radio.change(fn=update_node_badge_mode, inputs=node_badge_mode_radio, outputs=node_badge_output_text)

    # --- å…¶ä»–äº‹ä»¶å¤„ç† ---
    resolution_dropdown.change(fn=update_from_preset, inputs=resolution_dropdown, outputs=[resolution_dropdown, hua_width, hua_height, ratio_display])
    hua_width.change(fn=update_from_inputs, inputs=[hua_width, hua_height], outputs=[resolution_dropdown, ratio_display])
    hua_height.change(fn=update_from_inputs, inputs=[hua_width, hua_height], outputs=[resolution_dropdown, ratio_display])
    flip_btn.click(fn=flip_resolution, inputs=[hua_width, hua_height], outputs=[hua_width, hua_height])

    # JSON ä¸‹æ‹‰èœå•æ”¹å˜æ—¶ï¼Œæ›´æ–°æ‰€æœ‰ç›¸å…³ç»„ä»¶çš„å¯è§æ€§ã€é»˜è®¤å€¼ + è¾“å‡ºåŒºåŸŸå¯è§æ€§
    def update_ui_on_json_change(json_file):
        defaults = get_workflow_defaults_and_visibility(json_file, OUTPUT_DIR, resolution_prefixes, resolution_presets, MAX_DYNAMIC_COMPONENTS)
        
        updates = []

        # å•ä¾‹ç»„ä»¶
        updates.append(gr.update(visible=defaults["visible_image_input"]))
        updates.append(gr.update(visible=defaults["visible_video_input"]))
        updates.append(gr.update(visible=defaults["visible_neg_prompt"], value=defaults["default_neg_prompt"]))
        
        updates.append(gr.update(visible=defaults["visible_resolution"])) # resolution_row
        closest_preset = find_closest_preset(defaults["default_width"], defaults["default_height"], resolution_presets, resolution_prefixes)
        ratio_str = calculate_aspect_ratio(defaults["default_width"], defaults["default_height"])
        ratio_display_text = f"å½“å‰æ¯”ä¾‹: {ratio_str}"
        updates.append(gr.update(value=closest_preset)) # resolution_dropdown
        updates.append(gr.update(value=defaults["default_width"])) # hua_width
        updates.append(gr.update(value=defaults["default_height"])) # hua_height
        updates.append(gr.update(value=ratio_display_text)) # ratio_display

        updates.append(gr.update(visible=defaults["visible_checkpoint"], value=defaults["default_checkpoint"]))
        updates.append(gr.update(visible=defaults["visible_unet"], value=defaults["default_unet"]))
        updates.append(gr.update(visible=defaults["visible_seed_indicator"])) # seed_options_col
        updates.append(gr.update(visible=defaults["visible_image_output"])) # output_gallery
        updates.append(gr.update(visible=defaults["visible_video_output"])) # output_video

        # åŠ¨æ€ç»„ä»¶: GradioTextOk (positive_prompt_texts)
        dynamic_prompts_data = defaults["dynamic_components"]["GradioTextOk"]
        for i in range(MAX_DYNAMIC_COMPONENTS):
            if i < len(dynamic_prompts_data):
                node_data = dynamic_prompts_data[i]
                label = node_data.get("title", f"æ­£å‘æç¤º {i+1}")
                if label == node_data.get("id"): # if title was just node id
                    label = f"æ­£å‘æç¤º {i+1} (ID: {node_data.get('id')})"
                updates.append(gr.update(visible=True, label=label, value=node_data.get("value", "")))
            else:
                updates.append(gr.update(visible=False, label=f"æ­£å‘æç¤º {i+1}", value=""))
        
        # åŠ¨æ€ç»„ä»¶: Hua_LoraLoaderModelOnly (lora_dropdowns)
        dynamic_loras_data = defaults["dynamic_components"]["Hua_LoraLoaderModelOnly"]
        # è·å–å½“å‰çš„ Lora åˆ—è¡¨ç”¨äºæ£€æŸ¥
        current_lora_list = get_model_list("loras") # <--- è·å–æœ€æ–°åˆ—è¡¨
        print(f"[UI_UPDATE_DEBUG] Current Lora list for validation: {current_lora_list[:5]}... (Total: {len(current_lora_list)})") # æ‰“å°éƒ¨åˆ†åˆ—è¡¨ç”¨äºè°ƒè¯•

        for i in range(MAX_DYNAMIC_COMPONENTS):
            if i < len(dynamic_loras_data):
                node_data = dynamic_loras_data[i]
                lora_value_from_json = node_data.get("value", "None")
                label = node_data.get("title", f"Lora {i+1}")
                if label == node_data.get("id"):
                    label = f"Lora {i+1} (ID: {node_data.get('id')})"

                # --- æ–°å¢æ£€æŸ¥å’Œæ—¥å¿— ---
                final_lora_value_to_set = "None" # é»˜è®¤å€¼
                if lora_value_from_json != "None":
                    if lora_value_from_json in current_lora_list:
                        final_lora_value_to_set = lora_value_from_json
                        print(f"[UI_UPDATE_DEBUG] Lora {i+1} (ID: {node_data['id']}): Value '{lora_value_from_json}' found in list. Setting dropdown.")
                    else:
                        print(f"[UI_UPDATE_DEBUG] Lora {i+1} (ID: {node_data['id']}): Value '{lora_value_from_json}' NOT FOUND in current Lora list. Setting dropdown to 'None'.")
                else:
                     print(f"[UI_UPDATE_DEBUG] Lora {i+1} (ID: {node_data['id']}): Value from JSON is 'None'. Setting dropdown to 'None'.")
                # --- æ£€æŸ¥å’Œæ—¥å¿—ç»“æŸ ---

                updates.append(gr.update(visible=True, label=label, value=final_lora_value_to_set)) # <--- ä½¿ç”¨æ£€æŸ¥åçš„å€¼
            else:
                updates.append(gr.update(visible=False, label=f"Lora {i+1}", value="None"))

        # --- ä¸ºåˆ†è¾¨ç‡æ·»åŠ æ—¥å¿— ---
        print(f"[UI_UPDATE_DEBUG] Resolution: Setting Width={defaults['default_width']}, Height={defaults['default_height']}")
        # --- æ—¥å¿—ç»“æŸ ---

        # åŠ¨æ€ç»„ä»¶: HuaIntNode (int_inputs)
        dynamic_ints_data = defaults["dynamic_components"]["HuaIntNode"]
        for i in range(MAX_DYNAMIC_COMPONENTS):
            if i < len(dynamic_ints_data):
                node_data = dynamic_ints_data[i]
                node_id = node_data.get("id")
                node_title = node_data.get("title")
                # è·å–æ¥è‡ª inputs["name"] çš„å€¼ï¼Œå‡è®¾å®ƒè¢« get_workflow_defaults_and_visibility ä¼ é€’ä¸º name_from_node
                input_name_prefix = node_data.get("name_from_node")

                label_parts = []
                if input_name_prefix: # å¦‚æœ JSON ä¸­å®šä¹‰äº† name
                    label_parts.append(input_name_prefix)

                # æ·»åŠ èŠ‚ç‚¹æœ¬èº«çš„æ ‡é¢˜æˆ–é€šç”¨åç§°
                # å¦‚æœæœ‰ input_name_prefixï¼Œnode_title æ›´å¤šæ˜¯ä½œä¸ºè¡¥å……è¯´æ˜
                if node_title and node_title != node_id:
                    label_parts.append(node_title)
                elif not input_name_prefix: # åªæœ‰åœ¨æ²¡æœ‰ name å‰ç¼€æ—¶ï¼Œæ‰è€ƒè™‘æ·»åŠ é€šç”¨æè¿°ç¬¦ "æ•´æ•°"
                    label_parts.append(f"æ•´æ•°")

                # ç¡®ä¿æ ‡ç­¾ä¸ä¸ºç©ºï¼Œå¹¶æ·»åŠ  ID
                if not label_parts: # æç«¯æƒ…å†µä¸‹çš„å›é€€
                    label_parts.append(f"æ•´æ•° {i+1}")
                
                label = " - ".join(label_parts) + f" (ID: {node_id})"
                
                updates.append(gr.update(visible=True, label=label, value=node_data.get("value", 0)))
            else:
                updates.append(gr.update(visible=False, label=f"æ•´æ•° {i+1}", value=0))

        # åŠ¨æ€ç»„ä»¶: HuaFloatNode (float_inputs)
        dynamic_floats_data = defaults["dynamic_components"]["HuaFloatNode"]
        for i in range(MAX_DYNAMIC_COMPONENTS):
            if i < len(dynamic_floats_data):
                node_data = dynamic_floats_data[i]
                node_id = node_data.get("id")
                node_title = node_data.get("title")
                # è·å–æ¥è‡ª inputs["name"] çš„å€¼ï¼Œå‡è®¾å®ƒè¢« get_workflow_defaults_and_visibility ä¼ é€’ä¸º name_from_node
                input_name_prefix = node_data.get("name_from_node")

                label_parts = []
                if input_name_prefix: # å¦‚æœ JSON ä¸­å®šä¹‰äº† name
                    label_parts.append(input_name_prefix)

                # æ·»åŠ èŠ‚ç‚¹æœ¬èº«çš„æ ‡é¢˜æˆ–é€šç”¨åç§°
                # å¦‚æœæœ‰ input_name_prefixï¼Œnode_title æ›´å¤šæ˜¯ä½œä¸ºè¡¥å……è¯´æ˜
                if node_title and node_title != node_id:
                    label_parts.append(node_title)
                elif not input_name_prefix: # åªæœ‰åœ¨æ²¡æœ‰ name å‰ç¼€æ—¶ï¼Œæ‰è€ƒè™‘æ·»åŠ é€šç”¨æè¿°ç¬¦ "æµ®ç‚¹æ•°"
                    label_parts.append(f"æµ®ç‚¹æ•°")

                # ç¡®ä¿æ ‡ç­¾ä¸ä¸ºç©ºï¼Œå¹¶æ·»åŠ  ID
                if not label_parts: # æç«¯æƒ…å†µä¸‹çš„å›é€€
                    label_parts.append(f"æµ®ç‚¹æ•° {i+1}")
                
                label = " - ".join(label_parts) + f" (ID: {node_id})"
                
                updates.append(gr.update(visible=True, label=label, value=node_data.get("value", 0.0)))
            else:
                updates.append(gr.update(visible=False, label=f"æµ®ç‚¹æ•° {i+1}", value=0.0))
        
        return tuple(updates)

    json_dropdown.change(
        fn=update_ui_on_json_change,
        inputs=json_dropdown,
        outputs=[ 
            image_accordion, video_accordion, prompt_negative,
            resolution_row, resolution_dropdown, hua_width, hua_height, ratio_display,
            hua_checkpoint_dropdown, hua_unet_dropdown, seed_options_col,
            output_gallery, output_video,
            # Spread out the dynamic component lists into the outputs
            *positive_prompt_texts,
            *lora_dropdowns,
            *int_inputs,
            *float_inputs
        ]
    )

    # --- æ–°å¢ï¼šæ ¹æ®ç§å­æ¨¡å¼æ˜¾ç¤º/éšè—å›ºå®šç§å­è¾“å…¥æ¡† ---
    def toggle_fixed_seed_input(mode):
        return gr.update(visible=(mode == "å›ºå®š"))

    seed_mode_dropdown.change(
        fn=toggle_fixed_seed_input,
        inputs=seed_mode_dropdown,
        outputs=fixed_seed_input
    )
    # --- æ–°å¢ç»“æŸ ---

    refresh_button.click(
        fn=refresh_workflow_and_ui,
        inputs=[json_dropdown], # Pass the current value of json_dropdown
        outputs=[
            json_dropdown, # First output is for the dropdown itself
            # Then all the outputs that update_ui_on_json_change targets
            image_accordion, video_accordion, prompt_negative,
            resolution_row, resolution_dropdown, hua_width, hua_height, ratio_display,
            hua_checkpoint_dropdown, hua_unet_dropdown, seed_options_col,
            output_gallery, output_video,
            *positive_prompt_texts,
            *lora_dropdowns,
            *int_inputs,
            *float_inputs
        ]
    )

    # get_output_images is imported, needs OUTPUT_DIR
    load_output_button.click(fn=lambda: get_output_images(OUTPUT_DIR), inputs=[], outputs=output_preview_gallery)

    # --- ä¿®æ”¹è¿è¡ŒæŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ ---
    run_button.click(
        fn=run_queued_tasks,
        inputs=[
            input_image, input_video, 
            # Pass the lists of dynamic components directly
            *positive_prompt_texts, 
            prompt_negative, # Single negative prompt
            json_dropdown, hua_width, hua_height, 
            *lora_dropdowns,
            hua_checkpoint_dropdown, hua_unet_dropdown, 
            *float_inputs, 
            *int_inputs,
            seed_mode_dropdown, fixed_seed_input,
            queue_count
        ],
        outputs=[queue_status_display, output_gallery, output_video, main_output_tabs_component]
    )
    
    # interrupt_button_main_tab.click äº‹ä»¶å¤„ç†å™¨å·²è¢«ç§»é™¤

    # --- æ·»åŠ æ–°æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ ---
    clear_queue_button.click(fn=clear_queue, inputs=[], outputs=[queue_status_display])
    clear_history_button.click(fn=clear_history, inputs=[], outputs=[output_gallery, output_video, queue_status_display])
    sponsor_button.click(fn=show_sponsor_code, inputs=[], outputs=[sponsor_display])

    refresh_model_button.click(
        lambda: tuple(
            [gr.update(choices=get_model_list("loras")) for _ in range(MAX_DYNAMIC_COMPONENTS)] +
            [gr.update(choices=get_model_list("checkpoints")), gr.update(choices=get_model_list("unet"))]
        ),
        inputs=[],
        outputs=[*lora_dropdowns, hua_checkpoint_dropdown, hua_unet_dropdown]
    )

    # --- åˆå§‹åŠ è½½ ---
    def on_load_setup():
        json_files = get_json_files()
        # The number of outputs from update_ui_on_json_change is now:
        # 13 (single instance UI elements) + 4 * MAX_DYNAMIC_COMPONENTS (dynamic elements)
        # = 13 + 4 * 5 = 13 + 20 = 33
        
        if not json_files:
            print("æœªæ‰¾åˆ° JSON æ–‡ä»¶ï¼Œéšè—æ‰€æœ‰åŠ¨æ€ç»„ä»¶å¹¶è®¾ç½®é»˜è®¤å€¼")
            
            initial_updates = [
                gr.update(visible=False), # image_accordion
                gr.update(visible=False), # video_accordion
                gr.update(visible=False, value=""), # prompt_negative
                gr.update(visible=False), # resolution_row
                gr.update(value="custom"), # resolution_dropdown
                gr.update(value=512),      # hua_width
                gr.update(value=512),      # hua_height
                gr.update(value="å½“å‰æ¯”ä¾‹: 1:1"), # ratio_display
                gr.update(visible=False, value="None"), # hua_checkpoint_dropdown
                gr.update(visible=False, value="None"), # hua_unet_dropdown
                gr.update(visible=False), # seed_options_col
                gr.update(visible=False), # output_gallery
                gr.update(visible=False)  # output_video
            ]
            # Add updates for dynamic components (all hidden)
            for _ in range(MAX_DYNAMIC_COMPONENTS): # positive_prompt_texts
                initial_updates.append(gr.update(visible=False, label="æ­£å‘æç¤º", value=""))
            for _ in range(MAX_DYNAMIC_COMPONENTS): # lora_dropdowns
                initial_updates.append(gr.update(visible=False, label="Lora", value="None"))
            for _ in range(MAX_DYNAMIC_COMPONENTS): # int_inputs
                initial_updates.append(gr.update(visible=False, label="æ•´æ•°", value=0))
            for _ in range(MAX_DYNAMIC_COMPONENTS): # float_inputs
                initial_updates.append(gr.update(visible=False, label="æµ®ç‚¹æ•°", value=0.0))
            return tuple(initial_updates)
        else:
            default_json = json_files[0]
            print(f"åˆå§‹åŠ è½½ï¼Œæ£€æŸ¥é»˜è®¤ JSON: {default_json}")
            return update_ui_on_json_change(default_json) # This now returns a tuple of gr.update calls

    demo.load(
        fn=on_load_setup,
        inputs=[],
        outputs=[ # This list must exactly match the components updated by on_load_setup / update_ui_on_json_change
            image_accordion, video_accordion, prompt_negative,
            resolution_row, resolution_dropdown, hua_width, hua_height, ratio_display,
            hua_checkpoint_dropdown, hua_unet_dropdown, seed_options_col,
            output_gallery, output_video,
            *positive_prompt_texts,
            *lora_dropdowns,
            *int_inputs,
            *float_inputs
        ]
    )

    # --- æ·»åŠ æ—¥å¿—è½®è¯¢ Timer ---
    # æ¯ 0.1 ç§’è°ƒç”¨ fetch_and_format_logsï¼Œå¹¶å°†ç»“æœè¾“å‡ºåˆ° log_display (åŠ å¿«åˆ·æ–°ä»¥æ”¹å–„æ»šåŠ¨)
    log_timer = gr.Timer(0.1, active=True)  # æ¯ 0.1 ç§’è§¦å‘ä¸€æ¬¡
    log_timer.tick(fetch_and_format_logs, inputs=None, outputs=log_display)

    # --- ç³»ç»Ÿç›‘æ§æµåŠ è½½ ---
    # outputs éœ€è¦æŒ‡å‘åœ¨ gr.Blocks å†…å®šä¹‰çš„ floating_monitor_html_output å®ä¾‹
    # ç¡®ä¿ floating_monitor_html_output å˜é‡åœ¨ demo.load è°ƒç”¨æ—¶æ˜¯å¯è®¿é—®çš„
    # (å®ƒæ˜¯åœ¨ with gr.Blocks(...) ä¸Šä¸‹æ–‡ä¸­å®šä¹‰çš„ï¼Œæ‰€ä»¥ demo å¯¹è±¡çŸ¥é“å®ƒ)
    demo.load(fn=update_floating_monitors_stream, inputs=None, outputs=[floating_monitor_html_output], show_progress="hidden")

    # --- ComfyUI å®æ—¶é¢„è§ˆåŠ è½½ ---
    demo.load(
        fn=comfyui_previewer.get_update_generator(),
        inputs=[],
        outputs=[live_preview_image, live_preview_status],
        show_progress="hidden" # é€šå¸¸é¢„è§ˆä¸éœ€è¦è¿›åº¦æ¡
    )
    # å¯åŠ¨é¢„è§ˆå™¨çš„å·¥ä½œçº¿ç¨‹
    # demo.load(fn=comfyui_previewer.start_worker, inputs=[], outputs=[], show_progress="hidden")
    # ç›´æ¥åœ¨ Gradio çº¿ç¨‹å¯åŠ¨åè°ƒç”¨ start_worker æ›´å¯é 
    # æˆ–è€…åœ¨ on_load_setup ä¸­è°ƒç”¨


    # --- Gradio å¯åŠ¨ä»£ç  ---
def luanch_gradio(demo_instance): # æ¥æ”¶ demo å®ä¾‹
    # åœ¨ Gradio å¯åŠ¨å‰å¯åŠ¨é¢„è§ˆå™¨å·¥ä½œçº¿ç¨‹
    print("å‡†å¤‡å¯åŠ¨ ComfyUIPreviewer å·¥ä½œçº¿ç¨‹...")
    comfyui_previewer.start_worker()
    print("ComfyUIPreviewer å·¥ä½œçº¿ç¨‹å·²è¯·æ±‚å¯åŠ¨ã€‚")

    try:
        # å°è¯•æŸ¥æ‰¾å¯ç”¨ç«¯å£ï¼Œä» 7861 å¼€å§‹
        port = 7861
        while True:
            try:
                # share=True ä¼šå°è¯•åˆ›å»ºå…¬ç½‘é“¾æ¥ï¼Œå¯èƒ½éœ€è¦ç™»å½• huggingface
                # server_name="0.0.0.0" å…è®¸å±€åŸŸç½‘è®¿é—®
                # æ ¹æ® Gradio ç‰ˆæœ¬è°ƒæ•´å‚æ•°ä¼ é€’æ–¹å¼
                launch_kwargs = {
                    "server_name": "0.0.0.0",
                    "server_port": port,
                    "share": False,
                    "prevent_thread_lock": True
                }
                # Gradio 6.0+ å°† css ç§»åˆ° launch() æ–¹æ³•
                if GRADIO_SUPPORTS_NEW_API:
                    launch_kwargs["css"] = combined_css
                demo_instance.launch(**launch_kwargs)
                print(f"Gradio ç•Œé¢å·²åœ¨ http://127.0.0.1:{port} (æˆ–å±€åŸŸç½‘ IP) å¯åŠ¨")
                # å¯åŠ¨æˆåŠŸåæ‰“å¼€æœ¬åœ°é“¾æ¥
                webbrowser.open(f"http://127.0.0.1:{port}/")
                break # æˆåŠŸå¯åŠ¨ï¼Œé€€å‡ºå¾ªç¯
            except OSError as e:
                if "address already in use" in str(e).lower():
                    print(f"ç«¯å£ {port} å·²è¢«å ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç«¯å£...")
                    port += 1
                    if port > 7870: # é™åˆ¶å°è¯•èŒƒå›´
                        print("æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ (7861-7870)ã€‚")
                        break
                else:
                    print(f"å¯åŠ¨ Gradio æ—¶å‘ç”ŸæœªçŸ¥ OS é”™è¯¯: {e}")
                    break # å…¶ä»– OS é”™è¯¯ï¼Œé€€å‡º
            except Exception as e:
                 print(f"å¯åŠ¨ Gradio æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                 break # å…¶ä»–é”™è¯¯ï¼Œé€€å‡º
    except Exception as e:
        print(f"æ‰§è¡Œ luanch_gradio æ—¶å‡ºé”™: {e}")


# ä½¿ç”¨å®ˆæŠ¤çº¿ç¨‹ï¼Œè¿™æ ·ä¸»ç¨‹åºé€€å‡ºæ—¶ Gradio çº¿ç¨‹ä¹Ÿä¼šé€€å‡º
gradio_thread = threading.Thread(target=luanch_gradio, args=(demo,), daemon=True)
gradio_thread.start()

# æ³¨å†Œ atexit æ¸…ç†å‡½æ•°ï¼Œä»¥åœ¨ç¨‹åºé€€å‡ºæ—¶åœæ­¢ previewer worker
def cleanup_previewer_on_exit():
    print("Gradio åº”ç”¨æ­£åœ¨å…³é—­ï¼Œå°è¯•åœæ­¢ ComfyUIPreviewer å·¥ä½œçº¿ç¨‹...")
    if comfyui_previewer:
        comfyui_previewer.stop_worker()
    print("ComfyUIPreviewer å·¥ä½œçº¿ç¨‹å·²è¯·æ±‚åœæ­¢ã€‚")

atexit.register(cleanup_previewer_on_exit)


# ä¸»çº¿ç¨‹å¯ä»¥ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡æˆ–ç­‰å¾…ï¼Œè¿™é‡Œç®€å•åœ°ä¿æŒè¿è¡Œ
# æ³¨æ„ï¼šå¦‚æœè¿™æ˜¯æ’ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œä¸»çº¿ç¨‹å¯èƒ½æ˜¯ ComfyUI æœ¬èº«ï¼Œä¸éœ€è¦æ— é™å¾ªç¯
# print("ä¸»çº¿ç¨‹ç»§ç»­è¿è¡Œ... æŒ‰ Ctrl+C é€€å‡ºã€‚")
# try:
#     while True:
#         time.sleep(1)
# except KeyboardInterrupt:
#     print("æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
#     # demo.close() # å…³é—­ Gradio æœåŠ¡ (å¦‚æœéœ€è¦æ‰‹åŠ¨å…³é—­)
#     # cleanup_previewer_on_exit() # æ‰‹åŠ¨è°ƒç”¨æ¸…ç† (atexit åº”è¯¥ä¼šå¤„ç†)
